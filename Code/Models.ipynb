{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Lambda,Reshape,concatenate,Input, Embedding, LSTM\n",
    "from keras.layers import Dense,Dropout, Activation ,Flatten ,RepeatVector, Bidirectional,GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.activations import softmax\n",
    "from keras import regularizers\n",
    "\n",
    "from keras import backend as K, regularizers, constraints, initializers\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras.layers.convolutional import Conv1D,Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "from Attention import Attention\n",
    "\n",
    "from keras.layers import Concatenate,Dot\n",
    "from keras.layers import Permute, merge\n",
    "\n",
    "# FOR ATAE\n",
    "from AttentionwithContext import AttentionWithContext\n",
    "from Final import FinalSentenceRepresentation\n",
    "\n",
    "from final2 import Final2\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pickle.load(open(\"all_data.dat\",\"rb\"))\n",
    "\n",
    "input_i=a['sentence']\n",
    "input_t=a['target']\n",
    "\n",
    "input_t_IAN=a['target_for_IAN']\n",
    "\n",
    "embedding_matrix=a['embedding_matrix']\n",
    "\n",
    "sentiment= a['train_sentiment']\n",
    "\n",
    "v_sentence=a['v_sentence']\n",
    "v_target= a['v_target']\n",
    "v_sentiment= a['v_sentiment']\n",
    "v_target_IAN =a['v_target_IAN']\n",
    "\n",
    "vocab_size= a['vocab_size']\n",
    "aspect=a['aspect']\n",
    "aspect_y=a['v_aspect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aspect_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embedding_matrix', 'v_sentence', 'vocab_size', 'v_target_IAN', 'v_aspect', 'v_target', 'aspect', 'target_for_IAN', 'train_sentiment', 'target', 'sentence', 'v_sentiment'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[411, 292,   0,   0,   0],\n",
       "       [  2,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0],\n",
       "       [853,   0,   0,   0,   0],\n",
       "       [ 77,   0,   0,   0,   0],\n",
       "       [ 33,   0,   0,   0,   0],\n",
       "       [ 86,   0,   0,   0,   0],\n",
       "       [857,   0,   0,   0,   0],\n",
       "       [859,   0,   0,   0,   0],\n",
       "       [357,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_t_IAN[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_mse(y_true,y_pred):\n",
    "     return K.mean(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs for  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 442,   14, 1457, ...,  840,   31, 1460],\n",
       "       [ 288,   28,  289, ...,    0,    0,    0],\n",
       "       [1461,  219,   37, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [1426, 1265, 1213, ...,    0,    0,    0],\n",
       "       [3320, 1163, 3321, ...,    0,    0,    0],\n",
       "       [1240, 1337, 3323, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_context=input_i\n",
    "input_target=input_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(input_context[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(input_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.tile(input_t,11)\n",
    "input_target= target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_target[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX= [input_context, input_target]\n",
    "testX= [v_sentence,v_target]\n",
    "testY=v_sentiment\n",
    "trainY= sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=11\n",
    "#max_target_len=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_less= input_context[:100]\n",
    "#t_less = input_target[:100]\n",
    "#trainY_less= trainY[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#t_less[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_X=[v_sentence[:10],v_target[:10]]\n",
    "#test_Y=v_sentiment[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_AT(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag, em_dim):\n",
    "    \n",
    "    \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(max_length,),name='Target')\n",
    "  \n",
    "   \n",
    "    #print(input_target.shape)\n",
    "    #print(input_context.shape)\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    v_target = embedding(input_target)\n",
    "    \n",
    "    \n",
    "    #print(context.shape)\n",
    "    print(\"Target\" ,v_target.shape)\n",
    "\n",
    "    \n",
    "    #concat = concatenate(inputs =[target,context])\n",
    "    #print(concat.shape)\n",
    "    #inputs = Dropout(dropout)(concat)\n",
    "    #print(inputs.shape)   \n",
    "    \n",
    "    \n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(context)\n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(H)\n",
    "    H_all, H_last , _ = LSTM (lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"AT\")(H)\n",
    "\n",
    "    #print(H_all.shape , \"H_all before reduction\")\n",
    "    H_all_1 =GlobalAveragePooling1D()(H_all)\n",
    "    #print(H_all.shape , \"H_all after reduction\")\n",
    "\n",
    "    #Target = GlobalAveragePooling1D()(v_target)\n",
    "    #print(Target.shape , \"Target after reduction\")\n",
    "    \n",
    "    concat = concatenate(inputs =[v_target,H_all])\n",
    "    print(\"Concat\",concat.shape)\n",
    "    \n",
    "    r=AttentionWithContext(name='Attention')([H_all,concat])\n",
    "    \n",
    "    #print(\"h_ n \", H_last.shape)\n",
    "    \n",
    "\n",
    "    out=FinalSentenceRepresentation(name='Final')([r , H_all_1])\n",
    "    \n",
    "    #out=Dense(int((2*lstm_out+1)/2),activation='relu')(out)\n",
    "            \n",
    "    out= Dense(1, activation='sigmoid',  kernel_regularizer=regularizers.l2(0.01))(out)\n",
    "\n",
    "    #print(out.shape)\n",
    "    \n",
    "    AT_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    AT_model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = [sk_mse])\n",
    "    \n",
    "    \n",
    "    print(AT_model.summary())\n",
    "    \n",
    "    return AT_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (?, 11, 300)\n",
      "Concat (?, 11, 600)\n",
      "M1 (?, 11, 600)\n",
      "M (?, 11, 1)\n",
      "alpha (?, 11, 1)\n",
      "r (?, 300)\n",
      "H_last (?, 300)\n",
      "m1  (?, 300)\n",
      "m2.shape (?, 300)\n",
      "(?, 300) h_final\n",
      "OUT (?, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 11, 300)      997200      Context[0][0]                    \n",
      "                                                                 Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 11, 300)      721200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 11, 300)      721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Target (InputLayer)             (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "AT (LSTM)                       [(None, 11, 300), (N 721200      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 11, 600)      0           embedding_1[1][0]                \n",
      "                                                                 AT[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "Attention (AttentionWithContext (300, 1)             360600      AT[0][0]                         \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           AT[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "Final (FinalSentenceRepresentat (None, 1)            180301      Attention[0][0]                  \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           Final[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,701,703\n",
      "Trainable params: 2,704,503\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "AT_model = Model_AT(learning_rate=0.00069,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 8s 7ms/step - loss: 0.6996 - sk_mse: 0.0409 - val_loss: 0.7112 - val_sk_mse: 0.0483\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6912 - sk_mse: 0.0369 - val_loss: 0.7094 - val_sk_mse: 0.0474\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.6824 - sk_mse: 0.0326 - val_loss: 0.7064 - val_sk_mse: 0.0461\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.6774 - sk_mse: 0.0303 - val_loss: 0.7036 - val_sk_mse: 0.0447\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6728 - sk_mse: 0.0282 - val_loss: 0.7023 - val_sk_mse: 0.0443\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6683 - sk_mse: 0.0262 - val_loss: 0.7059 - val_sk_mse: 0.0460\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6678 - sk_mse: 0.0260 - val_loss: 0.7162 - val_sk_mse: 0.0508\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6640 - sk_mse: 0.0243 - val_loss: 0.7296 - val_sk_mse: 0.0571\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6632 - sk_mse: 0.0241 - val_loss: 0.7093 - val_sk_mse: 0.0478\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6587 - sk_mse: 0.0220 - val_loss: 0.7165 - val_sk_mse: 0.0513\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6548 - sk_mse: 0.0202 - val_loss: 0.7084 - val_sk_mse: 0.0476\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6561 - sk_mse: 0.0210 - val_loss: 0.7152 - val_sk_mse: 0.0509\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6519 - sk_mse: 0.0191 - val_loss: 0.7489 - val_sk_mse: 0.0662\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6548 - sk_mse: 0.0206 - val_loss: 0.7360 - val_sk_mse: 0.0602\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6485 - sk_mse: 0.0176 - val_loss: 0.7202 - val_sk_mse: 0.0534\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6461 - sk_mse: 0.0165 - val_loss: 0.7276 - val_sk_mse: 0.0569\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6430 - sk_mse: 0.0151 - val_loss: 0.7125 - val_sk_mse: 0.0498\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6430 - sk_mse: 0.0152 - val_loss: 0.7244 - val_sk_mse: 0.0554\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6424 - sk_mse: 0.0150 - val_loss: 0.7253 - val_sk_mse: 0.0557\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6395 - sk_mse: 0.0137 - val_loss: 0.7184 - val_sk_mse: 0.0527\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6418 - sk_mse: 0.0148 - val_loss: 0.7333 - val_sk_mse: 0.0596\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6421 - sk_mse: 0.0150 - val_loss: 0.7227 - val_sk_mse: 0.0546\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6410 - sk_mse: 0.0145 - val_loss: 0.7318 - val_sk_mse: 0.0593\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6362 - sk_mse: 0.0123 - val_loss: 0.7199 - val_sk_mse: 0.0536\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6340 - sk_mse: 0.0113 - val_loss: 0.7249 - val_sk_mse: 0.0560\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6319 - sk_mse: 0.0103 - val_loss: 0.7262 - val_sk_mse: 0.0565\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6321 - sk_mse: 0.0104 - val_loss: 0.7338 - val_sk_mse: 0.0602\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6338 - sk_mse: 0.0112 - val_loss: 0.7234 - val_sk_mse: 0.0553\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6332 - sk_mse: 0.0110 - val_loss: 0.7324 - val_sk_mse: 0.0595\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6340 - sk_mse: 0.0114 - val_loss: 0.7229 - val_sk_mse: 0.0552\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6306 - sk_mse: 0.0097 - val_loss: 0.7161 - val_sk_mse: 0.0520\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6293 - sk_mse: 0.0091 - val_loss: 0.7417 - val_sk_mse: 0.0640\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6294 - sk_mse: 0.0092 - val_loss: 0.7175 - val_sk_mse: 0.0526\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6294 - sk_mse: 0.0092 - val_loss: 0.7096 - val_sk_mse: 0.0491\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6297 - sk_mse: 0.0094 - val_loss: 0.7211 - val_sk_mse: 0.0545\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6282 - sk_mse: 0.0087 - val_loss: 0.7252 - val_sk_mse: 0.0562\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6288 - sk_mse: 0.0090 - val_loss: 0.7207 - val_sk_mse: 0.0541\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6289 - sk_mse: 0.0090 - val_loss: 0.7127 - val_sk_mse: 0.0503\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6278 - sk_mse: 0.0085 - val_loss: 0.7136 - val_sk_mse: 0.0507\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6254 - sk_mse: 0.0073 - val_loss: 0.7137 - val_sk_mse: 0.0509\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6251 - sk_mse: 0.0072 - val_loss: 0.7128 - val_sk_mse: 0.0503\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6253 - sk_mse: 0.0073 - val_loss: 0.7098 - val_sk_mse: 0.0490\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6264 - sk_mse: 0.0078 - val_loss: 0.7185 - val_sk_mse: 0.0532\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6267 - sk_mse: 0.0079 - val_loss: 0.7173 - val_sk_mse: 0.0524\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6262 - sk_mse: 0.0077 - val_loss: 0.7344 - val_sk_mse: 0.0606\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6257 - sk_mse: 0.0075 - val_loss: 0.7176 - val_sk_mse: 0.0525\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6249 - sk_mse: 0.0071 - val_loss: 0.7157 - val_sk_mse: 0.0518\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6240 - sk_mse: 0.0067 - val_loss: 0.7149 - val_sk_mse: 0.0514\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6245 - sk_mse: 0.0069 - val_loss: 0.7103 - val_sk_mse: 0.0493\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.6273 - sk_mse: 0.0083 - val_loss: 0.7219 - val_sk_mse: 0.0549\n"
     ]
    }
   ],
   "source": [
    "AT_model = AT_model.fit(x=trainX,y=trainY, epochs=50,batch_size=64,validation_data=(testX,testY))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Attention to our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_1(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag,em_dim):\n",
    "     \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "        \n",
    "    a = Bidirectional(LSTM(300, return_sequences=True,recurrent_dropout=dropout))(context)\n",
    "    \n",
    "    print(a.shape)\n",
    "\n",
    "    alpha = Attention()(a)\n",
    "    \n",
    "    x=Dense(300,activation='relu')(alpha)\n",
    "        \n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model= Model(inputs=input_context ,outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    model.compile(loss = 'mse', optimizer=optimizer,metrics = ['mae'])\n",
    "    \n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 600)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Context (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 11, 300)           997200    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 11, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 600)               611       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 2,620,812\n",
      "Trainable params: 1,623,612\n",
      "Non-trainable params: 997,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Our_model = define_model_1(learning_rate=0.001,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0400 - mean_absolute_error: 0.1737\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0346 - mean_absolute_error: 0.1584\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0286 - mean_absolute_error: 0.1389\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0285 - mean_absolute_error: 0.1391\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0239 - mean_absolute_error: 0.1239\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0219 - mean_absolute_error: 0.1186\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0182 - mean_absolute_error: 0.1066\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0160 - mean_absolute_error: 0.0992\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0155 - mean_absolute_error: 0.0967\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0124 - mean_absolute_error: 0.0866\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0104 - mean_absolute_error: 0.0791\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.0742\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.0733\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0073 - mean_absolute_error: 0.0656\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0064 - mean_absolute_error: 0.0620\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0057 - mean_absolute_error: 0.0572\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0050 - mean_absolute_error: 0.0537\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0049 - mean_absolute_error: 0.0530A: 2s - loss: 0.0058 - mean_absolute_\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0037 - mean_absolute_error: 0.0459\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0036 - mean_absolute_error: 0.0448\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0032 - mean_absolute_error: 0.0428\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0032 - mean_absolute_error: 0.0415\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0026 - mean_absolute_error: 0.0375\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0025 - mean_absolute_error: 0.0379\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0025 - mean_absolute_error: 0.0366\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0023 - mean_absolute_error: 0.0347\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0024 - mean_absolute_error: 0.0354\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0022 - mean_absolute_error: 0.0335\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0022 - mean_absolute_error: 0.0341\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0019 - mean_absolute_error: 0.0320\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0019 - mean_absolute_error: 0.0325\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0019 - mean_absolute_error: 0.0313\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0018 - mean_absolute_error: 0.0302\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0017 - mean_absolute_error: 0.0296\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0016 - mean_absolute_error: 0.0284\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0016 - mean_absolute_error: 0.0286\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0017 - mean_absolute_error: 0.0293\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0015 - mean_absolute_error: 0.0265\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0014 - mean_absolute_error: 0.0267\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0014 - mean_absolute_error: 0.0265\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0014 - mean_absolute_error: 0.0254\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0015 - mean_absolute_error: 0.0268A: 2s - loss: 0.0017 - mean_absolu\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0014 - mean_absolute_error: 0.0266\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0014 - mean_absolute_error: 0.0262\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0015 - mean_absolute_error: 0.0264\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0012 - mean_absolute_error: 0.0235\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0012 - mean_absolute_error: 0.0234\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0012 - mean_absolute_error: 0.0235\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0014 - mean_absolute_error: 0.0256\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0012 - mean_absolute_error: 0.0239\n"
     ]
    }
   ],
   "source": [
    "Our_model =Our_model.fit(x=input_context,y=trainY, epochs=50,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AT-AE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_ATAE(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag, em_dim):\n",
    "    \n",
    "    \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(max_length,),name='Target')\n",
    "  \n",
    "   \n",
    "    #print(input_target.shape)\n",
    "    #print(input_context.shape)\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    v_target = embedding(input_target)\n",
    "    \n",
    "    #print(context.shape)\n",
    "    print(\"Target\" ,v_target.shape)\n",
    "\n",
    "    \n",
    "    concat = concatenate(inputs =[v_target,context])\n",
    "    print(concat.shape)\n",
    "    inputs = Dropout(dropout)(concat)\n",
    "    print(inputs.shape)   \n",
    "    \n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(inputs)\n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(H)\n",
    "    H_all, H_last , _ = LSTM (lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"ATAE\")(H)\n",
    "\n",
    "\n",
    "    H_all_1 = GlobalAveragePooling1D()(H_all)\n",
    "    print(H_all.shape , \"H_all after reduction\")\n",
    "    \n",
    "    concat = concatenate(inputs =[v_target,H_all])\n",
    "    print(\"Concat\",concat.shape)\n",
    "    \n",
    "    r=AttentionWithContext(name='Attention')([H_all,concat])\n",
    "    \n",
    "    #print(\"h_ n \", H_last.shape)\n",
    "    \n",
    "    \n",
    "    out=FinalSentenceRepresentation(name='Final')([r , H_all_1])\n",
    "\n",
    "    out= Dense(1, activation='sigmoid',  kernel_regularizer=regularizers.l2(0.01))(out)\n",
    "\n",
    "    #print(out.shape)\n",
    "    \n",
    "    ATAE_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    ATAE_model.compile(optimizer = optimizer, loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    \n",
    "    print(ATAE_model.summary())\n",
    "    \n",
    "    return ATAE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (?, 11, 300)\n",
      "(?, 11, 600)\n",
      "(?, 11, 600)\n",
      "(?, ?, 300) H_all after reduction\n",
      "Concat (?, 11, 600)\n",
      "M1 (?, 11, 600)\n",
      "M (?, 11, 1)\n",
      "alpha (?, 11, 1)\n",
      "r (?, 300)\n",
      "H_last (?, 300)\n",
      "m1  (?, 300)\n",
      "m2.shape (?, 300)\n",
      "(?, 300) h_final\n",
      "OUT (?, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Target (InputLayer)             (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 11, 300)      997200      Context[0][0]                    \n",
      "                                                                 Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 11, 600)      0           embedding_4[1][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 11, 600)      0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 11, 300)      1081200     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 11, 300)      721200      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ATAE (LSTM)                     [(None, 11, 300), (N 721200      lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 11, 600)      0           embedding_4[1][0]                \n",
      "                                                                 ATAE[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Attention (AttentionWithContext (300, 1)             360600      ATAE[0][0]                       \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 300)          0           ATAE[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Final (FinalSentenceRepresentat (None, 1)            180301      Attention[0][0]                  \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            2           Final[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,061,703\n",
      "Trainable params: 3,064,503\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ATAE_model = Model_ATAE(learning_rate=0.001,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 10s 8ms/step - loss: 0.0628 - mean_absolute_error: 0.1714 - val_loss: 0.0688 - val_mean_absolute_error: 0.1748\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0585 - mean_absolute_error: 0.1605 - val_loss: 0.0702 - val_mean_absolute_error: 0.1753\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0553 - mean_absolute_error: 0.1500 - val_loss: 0.0670 - val_mean_absolute_error: 0.1739\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0535 - mean_absolute_error: 0.1465 - val_loss: 0.0655 - val_mean_absolute_error: 0.1740\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0510 - mean_absolute_error: 0.1422 - val_loss: 0.0656 - val_mean_absolute_error: 0.1717\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0500 - mean_absolute_error: 0.1389 - val_loss: 0.0625 - val_mean_absolute_error: 0.1716\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0499 - mean_absolute_error: 0.1426 - val_loss: 0.0621 - val_mean_absolute_error: 0.1695\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0462 - mean_absolute_error: 0.1329 - val_loss: 0.0641 - val_mean_absolute_error: 0.1748\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0457 - mean_absolute_error: 0.1319 - val_loss: 0.0668 - val_mean_absolute_error: 0.1783\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0456 - mean_absolute_error: 0.1334 - val_loss: 0.0658 - val_mean_absolute_error: 0.1784\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0441 - mean_absolute_error: 0.1314 - val_loss: 0.0645 - val_mean_absolute_error: 0.1767\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0443 - mean_absolute_error: 0.1332 - val_loss: 0.0641 - val_mean_absolute_error: 0.1756\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0421 - mean_absolute_error: 0.1258 - val_loss: 0.0607 - val_mean_absolute_error: 0.1707\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0420 - mean_absolute_error: 0.1264 - val_loss: 0.0603 - val_mean_absolute_error: 0.1706\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0413 - mean_absolute_error: 0.1260 - val_loss: 0.0619 - val_mean_absolute_error: 0.1745\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.0397 - mean_absolute_error: 0.1233 - val_loss: 0.0604 - val_mean_absolute_error: 0.1703\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0379 - mean_absolute_error: 0.1174 - val_loss: 0.0634 - val_mean_absolute_error: 0.1768\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0376 - mean_absolute_error: 0.1177 - val_loss: 0.0604 - val_mean_absolute_error: 0.1754\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0364 - mean_absolute_error: 0.1177 - val_loss: 0.0662 - val_mean_absolute_error: 0.1845\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0362 - mean_absolute_error: 0.1145 - val_loss: 0.0598 - val_mean_absolute_error: 0.1751\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0334 - mean_absolute_error: 0.1101 - val_loss: 0.0607 - val_mean_absolute_error: 0.1773\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0350 - mean_absolute_error: 0.1153 - val_loss: 0.0604 - val_mean_absolute_error: 0.1775\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0345 - mean_absolute_error: 0.1139 - val_loss: 0.0576 - val_mean_absolute_error: 0.1731\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0336 - mean_absolute_error: 0.1109 - val_loss: 0.0611 - val_mean_absolute_error: 0.1790\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0320 - mean_absolute_error: 0.1094 - val_loss: 0.0596 - val_mean_absolute_error: 0.1774\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0315 - mean_absolute_error: 0.1060 - val_loss: 0.0593 - val_mean_absolute_error: 0.1763\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0310 - mean_absolute_error: 0.1058 - val_loss: 0.0590 - val_mean_absolute_error: 0.1787\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0300 - mean_absolute_error: 0.1064 - val_loss: 0.0635 - val_mean_absolute_error: 0.1843\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.0306 - mean_absolute_error: 0.1085 - val_loss: 0.0627 - val_mean_absolute_error: 0.1831\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0282 - mean_absolute_error: 0.1020 - val_loss: 0.0587 - val_mean_absolute_error: 0.1801\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.0272 - mean_absolute_error: 0.0998 - val_loss: 0.0612 - val_mean_absolute_error: 0.1820\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0278 - mean_absolute_error: 0.1000 - val_loss: 0.0642 - val_mean_absolute_error: 0.1866\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0276 - mean_absolute_error: 0.1018 - val_loss: 0.0588 - val_mean_absolute_error: 0.1781\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0264 - mean_absolute_error: 0.0998 - val_loss: 0.0575 - val_mean_absolute_error: 0.1778\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.0261 - mean_absolute_error: 0.0987 - val_loss: 0.0597 - val_mean_absolute_error: 0.1829\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0250 - mean_absolute_error: 0.0962 - val_loss: 0.0626 - val_mean_absolute_error: 0.1875\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0249 - mean_absolute_error: 0.0964 - val_loss: 0.0611 - val_mean_absolute_error: 0.1826\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0257 - mean_absolute_error: 0.0994 - val_loss: 0.0609 - val_mean_absolute_error: 0.1867\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0229 - mean_absolute_error: 0.0924 - val_loss: 0.0603 - val_mean_absolute_error: 0.1851\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0228 - mean_absolute_error: 0.0903 - val_loss: 0.0602 - val_mean_absolute_error: 0.1838\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0214 - mean_absolute_error: 0.0876 - val_loss: 0.0623 - val_mean_absolute_error: 0.1883\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0208 - mean_absolute_error: 0.0870 - val_loss: 0.0578 - val_mean_absolute_error: 0.1827\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0208 - mean_absolute_error: 0.0885 - val_loss: 0.0575 - val_mean_absolute_error: 0.1820\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0209 - mean_absolute_error: 0.0882 - val_loss: 0.0592 - val_mean_absolute_error: 0.1848\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0187 - mean_absolute_error: 0.0834 - val_loss: 0.0564 - val_mean_absolute_error: 0.1809\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0196 - mean_absolute_error: 0.0854 - val_loss: 0.0575 - val_mean_absolute_error: 0.1787\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0199 - mean_absolute_error: 0.0874 - val_loss: 0.0570 - val_mean_absolute_error: 0.1816\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0193 - mean_absolute_error: 0.0856 - val_loss: 0.0572 - val_mean_absolute_error: 0.1831\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0191 - mean_absolute_error: 0.0861 - val_loss: 0.0616 - val_mean_absolute_error: 0.1911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0192 - mean_absolute_error: 0.0865 - val_loss: 0.0578 - val_mean_absolute_error: 0.1840\n"
     ]
    }
   ],
   "source": [
    "ATAE_model = ATAE_model.fit(x=trainX,y=trainY, epochs=50,batch_size=64,validation_data=(testX,testY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'>\n",
    "\n",
    "\n",
    "loss: 0.0192 - mean_absolute_error: 0.0865\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATAE_model.save('ATAE_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Model_AE(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag, em_dim):\n",
    "     \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(max_length,),name='Target')\n",
    "  \n",
    "   \n",
    "    #print(input_target.shape)\n",
    "    #print(input_context.shape)\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    v_target = embedding(input_target)\n",
    "    \n",
    "    #print(context.shape)\n",
    "    print(\"Target\" ,v_target.shape)\n",
    "\n",
    "    \n",
    "    concat = concatenate(inputs =[v_target,context])\n",
    "    print(concat.shape)\n",
    "    inputs = Dropout(dropout)(concat)\n",
    "    print(inputs.shape)   \n",
    "    \n",
    "    H_last = Bidirectional(LSTM (lstm_out, recurrent_dropout=dropout,name=\"ATAE\"))(inputs)\n",
    "    \n",
    "    x=Dense(300,activation='relu')(H_last)\n",
    "        \n",
    "    out=Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    #print(out.shape)\n",
    "    \n",
    "    AE_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    AE_model.compile(optimizer = optimizer, loss = 'mse', metrics = ['mae'])\n",
    "    \n",
    "    \n",
    "    print(AE_model.summary())\n",
    "    \n",
    "    return AE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (?, 11, 300)\n",
      "(?, 11, 600)\n",
      "(?, 11, 600)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Target (InputLayer)             (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 11, 300)      997200      Context[0][0]                    \n",
      "                                                                 Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11, 600)      0           embedding_6[1][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 11, 600)      0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 600)          2162400     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          180300      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            301         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,340,201\n",
      "Trainable params: 2,343,001\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AE_model = Model_AE(learning_rate=0.001,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0418 - mean_absolute_error: 0.1735 - val_loss: 0.0438 - val_mean_absolute_error: 0.1739\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0346 - mean_absolute_error: 0.1582 - val_loss: 0.0459 - val_mean_absolute_error: 0.1762\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0302 - mean_absolute_error: 0.1425 - val_loss: 0.0450 - val_mean_absolute_error: 0.1754\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0276 - mean_absolute_error: 0.1354 - val_loss: 0.0459 - val_mean_absolute_error: 0.1768\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0260 - mean_absolute_error: 0.1301 - val_loss: 0.0465 - val_mean_absolute_error: 0.1752\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0240 - mean_absolute_error: 0.1233 - val_loss: 0.0469 - val_mean_absolute_error: 0.1759\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0221 - mean_absolute_error: 0.1176 - val_loss: 0.0480 - val_mean_absolute_error: 0.1797\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0209 - mean_absolute_error: 0.1126 - val_loss: 0.0494 - val_mean_absolute_error: 0.1793\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0191 - mean_absolute_error: 0.1087 - val_loss: 0.0469 - val_mean_absolute_error: 0.1777\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0193 - mean_absolute_error: 0.1076 - val_loss: 0.0497 - val_mean_absolute_error: 0.1787\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0177 - mean_absolute_error: 0.1021 - val_loss: 0.0508 - val_mean_absolute_error: 0.1831\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0166 - mean_absolute_error: 0.0977 - val_loss: 0.0472 - val_mean_absolute_error: 0.1780\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0156 - mean_absolute_error: 0.0955 - val_loss: 0.0482 - val_mean_absolute_error: 0.1784\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0150 - mean_absolute_error: 0.0931 - val_loss: 0.0488 - val_mean_absolute_error: 0.1795\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0143 - mean_absolute_error: 0.0910 - val_loss: 0.0524 - val_mean_absolute_error: 0.1878\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0133 - mean_absolute_error: 0.0872 - val_loss: 0.0478 - val_mean_absolute_error: 0.1762\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0130 - mean_absolute_error: 0.0839 - val_loss: 0.0500 - val_mean_absolute_error: 0.1805\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.0128 - mean_absolute_error: 0.0840 - val_loss: 0.0486 - val_mean_absolute_error: 0.1804\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0103 - mean_absolute_error: 0.0769 - val_loss: 0.0516 - val_mean_absolute_error: 0.1855\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0788 - val_loss: 0.0510 - val_mean_absolute_error: 0.1848\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0101 - mean_absolute_error: 0.0756 - val_loss: 0.0528 - val_mean_absolute_error: 0.1844\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0774 - val_loss: 0.0482 - val_mean_absolute_error: 0.1791\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0093 - mean_absolute_error: 0.0734 - val_loss: 0.0479 - val_mean_absolute_error: 0.1775\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0087 - mean_absolute_error: 0.0705 - val_loss: 0.0504 - val_mean_absolute_error: 0.1846\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0086 - mean_absolute_error: 0.0696 - val_loss: 0.0519 - val_mean_absolute_error: 0.1855\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0077 - mean_absolute_error: 0.0663 - val_loss: 0.0526 - val_mean_absolute_error: 0.1846\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0079 - mean_absolute_error: 0.0660 - val_loss: 0.0532 - val_mean_absolute_error: 0.1856\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0078 - mean_absolute_error: 0.0667 - val_loss: 0.0526 - val_mean_absolute_error: 0.1854\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0076 - mean_absolute_error: 0.0649 - val_loss: 0.0500 - val_mean_absolute_error: 0.1821\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0059 - mean_absolute_error: 0.0587 - val_loss: 0.0550 - val_mean_absolute_error: 0.1904\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0064 - mean_absolute_error: 0.0595 - val_loss: 0.0545 - val_mean_absolute_error: 0.1877\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0068 - mean_absolute_error: 0.0606 - val_loss: 0.0543 - val_mean_absolute_error: 0.1878\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0065 - mean_absolute_error: 0.0604 - val_loss: 0.0551 - val_mean_absolute_error: 0.1905\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0056 - mean_absolute_error: 0.0549 - val_loss: 0.0536 - val_mean_absolute_error: 0.1864\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0053 - mean_absolute_error: 0.0551 - val_loss: 0.0540 - val_mean_absolute_error: 0.1867\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0063 - mean_absolute_error: 0.0581 - val_loss: 0.0529 - val_mean_absolute_error: 0.1858\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0057 - mean_absolute_error: 0.0563 - val_loss: 0.0567 - val_mean_absolute_error: 0.1912\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0054 - mean_absolute_error: 0.0550 - val_loss: 0.0535 - val_mean_absolute_error: 0.1863\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0046 - mean_absolute_error: 0.0511 - val_loss: 0.0561 - val_mean_absolute_error: 0.1900\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0047 - mean_absolute_error: 0.0517 - val_loss: 0.0562 - val_mean_absolute_error: 0.1901\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0046 - mean_absolute_error: 0.0524 - val_loss: 0.0562 - val_mean_absolute_error: 0.1925\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0044 - mean_absolute_error: 0.0506 - val_loss: 0.0543 - val_mean_absolute_error: 0.1918\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0044 - mean_absolute_error: 0.0493 - val_loss: 0.0545 - val_mean_absolute_error: 0.1898\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0044 - mean_absolute_error: 0.0491 - val_loss: 0.0564 - val_mean_absolute_error: 0.1928\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0039 - mean_absolute_error: 0.0474 - val_loss: 0.0539 - val_mean_absolute_error: 0.1882\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0035 - mean_absolute_error: 0.0454 - val_loss: 0.0561 - val_mean_absolute_error: 0.1919\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0040 - mean_absolute_error: 0.0472 - val_loss: 0.0557 - val_mean_absolute_error: 0.1905\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0038 - mean_absolute_error: 0.0462 - val_loss: 0.0532 - val_mean_absolute_error: 0.1856\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0039 - mean_absolute_error: 0.0464 - val_loss: 0.0530 - val_mean_absolute_error: 0.1849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0042 - mean_absolute_error: 0.0473 - val_loss: 0.0564 - val_mean_absolute_error: 0.1911\n"
     ]
    }
   ],
   "source": [
    "AE_model = AE_model.fit(x=trainX,y=trainY, epochs=50,batch_size=64,validation_data=(testX,testY))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_model.save('AE_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# IAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor = Dense(1, activation = \"tanh\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, avg,shape):\n",
    "    \n",
    "    avg = RepeatVector(shape)(avg)\n",
    "    #print(\"avg\",avg.shape)\n",
    "    \n",
    "    concat = concatenator([h, avg])\n",
    "    #print(\"concat\",concat.shape)\n",
    "    \n",
    "    e = densor(concat)\n",
    "    #print(\"e\",e.shape)\n",
    "\n",
    "    alphas = activator(e)\n",
    "    #print(\"alphas\",alphas.shape)\n",
    "\n",
    "    context = dotor([alphas, h])\n",
    "    #print(\"context\",context.shape)\n",
    "    \n",
    "    return K.sum(context, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Model_IAN(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag, em_dim):\n",
    "    \n",
    "    input_context = Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(5,),name='Target')\n",
    "    \n",
    "    print(\"Target \",input_target.shape)\n",
    "    print(\"Context\" ,input_context.shape)\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    embedding_T=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=5,trainable = em_trainable_flag)\n",
    "\n",
    "    context=embedding(input_context)\n",
    "    target= embedding_T(input_target)\n",
    "    print(\"Target_embedding\",target.shape)\n",
    "    print(\"Context_embedding\", context.shape)\n",
    " \n",
    "    H_c , _ , _ = LSTM( lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"LSTM_C\")(context)\n",
    "    H_t , _ , _ = LSTM( lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"LSTM_T\")(target)\n",
    "\n",
    "    print(\"hc\", H_c.shape)\n",
    "    print(\"ht\",H_t.shape)\n",
    "    \n",
    "    c_avg = GlobalAveragePooling1D(name='POOL_C')(H_c)  \n",
    "    t_avg = GlobalAveragePooling1D(name='POOL_T')(H_t)\n",
    "    \n",
    "    print(\"C_AVG\", c_avg.shape)\n",
    "    print(\"t_avg\",t_avg.shape)\n",
    "    \n",
    "\n",
    "    c_r = Lambda(lambda x: one_step_attention(x[0],x[1],11))([H_c,t_avg])\n",
    "    t_r = Lambda(lambda x: one_step_attention(x[0],x[1],5))([H_t,c_avg])\n",
    "    \n",
    "    print(\"c_r\",c_r.shape)\n",
    "    print(\"t_r\",t_r.shape)\n",
    "   \n",
    "    d = concatenate(inputs=[c_r , t_r])\n",
    "    \n",
    "    print(\"d\",d.shape)\n",
    "    \n",
    "    out= Dense(300, activation='relu')(d)\n",
    "\n",
    "    \n",
    "    out= Dense(1, activation='sigmoid',W_regularizer=regularizers.l2(0.001))(out)\n",
    "\n",
    "\n",
    "    print(\"out\", out.shape)\n",
    "    \n",
    "    IAN_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    IAN_model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    print( IAN_model.summary())\n",
    "    \n",
    "    return  IAN_model\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target  (?, 5)\n",
      "Context (?, 11)\n",
      "Target_embedding (?, 5, 300)\n",
      "Context_embedding (?, 11, 300)\n",
      "hc (?, ?, 300)\n",
      "ht (?, ?, 300)\n",
      "C_AVG (?, 300)\n",
      "t_avg (?, 300)\n",
      "c_r (?, 300)\n",
      "t_r (?, 300)\n",
      "d (?, 600)\n",
      "out (?, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Target (InputLayer)             (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 11, 300)      997200      Context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)        (None, 5, 300)       997200      Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_C (LSTM)                   [(None, 11, 300), (N 721200      embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_T (LSTM)                   [(None, 5, 300), (No 721200      embedding_34[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "POOL_T (GlobalAveragePooling1D) (None, 300)          0           LSTM_T[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "POOL_C (GlobalAveragePooling1D) (None, 300)          0           LSTM_C[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 300)          0           LSTM_C[0][0]                     \n",
      "                                                                 POOL_T[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 300)          0           LSTM_T[0][0]                     \n",
      "                                                                 POOL_C[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 600)          0           lambda_34[0][0]                  \n",
      "                                                                 lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 300)          180300      concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 1)            301         dense_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,617,401\n",
      "Trainable params: 1,623,001\n",
      "Non-trainable params: 1,994,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simcy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n"
     ]
    }
   ],
   "source": [
    "IAN_model=Model_IAN(learning_rate=0.01,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_IAN= [input_context,input_t_IAN]\n",
    "testX_IAN=[v_sentence,v_target_IAN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 10s 8ms/step - loss: 0.2205 - mean_absolute_error: 0.4191 - val_loss: 0.2868 - val_mean_absolute_error: 0.4898\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2341 - mean_absolute_error: 0.4391 - val_loss: 0.2861 - val_mean_absolute_error: 0.4898\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2335 - mean_absolute_error: 0.4391 - val_loss: 0.2857 - val_mean_absolute_error: 0.4898\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2332 - mean_absolute_error: 0.4391 - val_loss: 0.2854 - val_mean_absolute_error: 0.4898\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2330 - mean_absolute_error: 0.4391 - val_loss: 0.2853 - val_mean_absolute_error: 0.4898\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2328 - mean_absolute_error: 0.4391 - val_loss: 0.2852 - val_mean_absolute_error: 0.4898\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2327 - mean_absolute_error: 0.4391 - val_loss: 0.2851 - val_mean_absolute_error: 0.4898\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2327 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2422 - mean_absolute_error: 0.4481 - val_loss: 0.2872 - val_mean_absolute_error: 0.4898\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2354 - mean_absolute_error: 0.4391 - val_loss: 0.2877 - val_mean_absolute_error: 0.4898\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2350 - mean_absolute_error: 0.4391 - val_loss: 0.2869 - val_mean_absolute_error: 0.4898\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.2342 - mean_absolute_error: 0.4391 - val_loss: 0.2862 - val_mean_absolute_error: 0.4898\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.2336 - mean_absolute_error: 0.4391 - val_loss: 0.2858 - val_mean_absolute_error: 0.4898\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 4s 3ms/step - loss: 0.2332 - mean_absolute_error: 0.4391 - val_loss: 0.2855 - val_mean_absolute_error: 0.4898\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2330 - mean_absolute_error: 0.4391 - val_loss: 0.2853 - val_mean_absolute_error: 0.4898\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2328 - mean_absolute_error: 0.4391 - val_loss: 0.2851 - val_mean_absolute_error: 0.4898\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2327 - mean_absolute_error: 0.4391 - val_loss: 0.2851 - val_mean_absolute_error: 0.4898\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2327 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2850 - val_mean_absolute_error: 0.4898\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2326 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2325 - mean_absolute_error: 0.4391 - val_loss: 0.2849 - val_mean_absolute_error: 0.4898\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2246 - mean_absolute_error: 0.4295 - val_loss: 0.2856 - val_mean_absolute_error: 0.4898\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2370 - mean_absolute_error: 0.4391 - val_loss: 0.2927 - val_mean_absolute_error: 0.4898\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2413 - mean_absolute_error: 0.4391 - val_loss: 0.2943 - val_mean_absolute_error: 0.4898\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2420 - mean_absolute_error: 0.4391 - val_loss: 0.2945 - val_mean_absolute_error: 0.4898\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2421 - mean_absolute_error: 0.4391 - val_loss: 0.2945 - val_mean_absolute_error: 0.4898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.2421 - mean_absolute_error: 0.4391 - val_loss: 0.2945 - val_mean_absolute_error: 0.4898\n"
     ]
    }
   ],
   "source": [
    "IAN_model = IAN_model.fit(x=trainX_IAN,y=trainY, epochs=50,batch_size=64,validation_data=(testX_IAN,testY))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAN_model.save('IAN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'>\n",
    "After 50 epochs :\n",
    "loss: 0.2421 - mean_absolute_error: 0.4391 - val_loss: 0.2945 - val_mean_absolute_error: 0.4898\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAN with One word target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Model_IAN_1(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag, em_dim):\n",
    "    \n",
    "    input_context = Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(11,),name='Target')\n",
    "    \n",
    "    print(\"Target \",input_target.shape)\n",
    "    print(\"Context\" ,input_context.shape)\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "\n",
    "    context=embedding(input_context)\n",
    "    target= embedding(input_target)\n",
    "    print(\"Target_embedding\",target.shape)\n",
    "    print(\"Context_embedding\", context.shape)\n",
    " \n",
    "    H_c , _ , _ = LSTM( lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"LSTM_C\")(context)\n",
    "    H_t , _ , _ = LSTM( lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"LSTM_T\")(target)\n",
    "\n",
    "    print(\"hc\", H_c.shape)\n",
    "    print(\"ht\",H_t.shape)\n",
    "    \n",
    "    c_avg = GlobalAveragePooling1D(name='POOL_C')(H_c)  \n",
    "    t_avg = GlobalAveragePooling1D(name='POOL_T')(H_t)\n",
    "    \n",
    "    print(\"C_AVG\", c_avg.shape)\n",
    "    print(\"t_avg\",t_avg.shape)\n",
    "    \n",
    "\n",
    "    c_r = Lambda(lambda x: one_step_attention(x[0],x[1],11))([H_c,t_avg])\n",
    "    t_r = Lambda(lambda x: one_step_attention(x[0],x[1],11))([H_t,c_avg])\n",
    "    \n",
    "    print(\"c_r\",c_r.shape)\n",
    "    print(\"t_r\",t_r.shape)\n",
    "   \n",
    "    d = concatenate(inputs=[c_r , t_r])\n",
    "    \n",
    "    print(\"d\",d.shape)\n",
    "    \n",
    "    out= Dense(300, activation='relu')(d)\n",
    "\n",
    "    \n",
    "    out= Dense(1, activation='sigmoid',W_regularizer=regularizers.l2(0.001))(out)\n",
    "\n",
    "\n",
    "    print(\"out\", out.shape)\n",
    "    \n",
    "    IAN_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    IAN_model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    print( IAN_model.summary())\n",
    "    \n",
    "    return  IAN_model\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target  (?, 11)\n",
      "Context (?, 11)\n",
      "Target_embedding (?, 11, 300)\n",
      "Context_embedding (?, 11, 300)\n",
      "hc (?, ?, 300)\n",
      "ht (?, ?, 300)\n",
      "C_AVG (?, 300)\n",
      "t_avg (?, 300)\n",
      "c_r (?, 300)\n",
      "t_r (?, 300)\n",
      "d (?, 600)\n",
      "out (?, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Target (InputLayer)             (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, 11, 300)      997200      Context[0][0]                    \n",
      "                                                                 Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_C (LSTM)                   [(None, 11, 300), (N 721200      embedding_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_T (LSTM)                   [(None, 11, 300), (N 721200      embedding_32[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "POOL_T (GlobalAveragePooling1D) (None, 300)          0           LSTM_T[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "POOL_C (GlobalAveragePooling1D) (None, 300)          0           LSTM_C[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 300)          0           LSTM_C[0][0]                     \n",
      "                                                                 POOL_T[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 300)          0           LSTM_T[0][0]                     \n",
      "                                                                 POOL_C[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 600)          0           lambda_32[0][0]                  \n",
      "                                                                 lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 300)          180300      concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1)            301         dense_32[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,620,201\n",
      "Trainable params: 1,623,001\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simcy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n"
     ]
    }
   ],
   "source": [
    "IAN_model_1=Model_IAN_1(learning_rate=0.01,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 10s 8ms/step - loss: 0.0492 - mean_absolute_error: 0.1824 - val_loss: 0.0499 - val_mean_absolute_error: 0.1818\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0378 - mean_absolute_error: 0.1585 - val_loss: 0.0502 - val_mean_absolute_error: 0.1811\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0330 - mean_absolute_error: 0.1476 - val_loss: 0.0513 - val_mean_absolute_error: 0.1821\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0302 - mean_absolute_error: 0.1407 - val_loss: 0.0495 - val_mean_absolute_error: 0.1789\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0271 - mean_absolute_error: 0.1323 - val_loss: 0.0493 - val_mean_absolute_error: 0.1782\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0247 - mean_absolute_error: 0.1242 - val_loss: 0.0473 - val_mean_absolute_error: 0.1760\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0230 - mean_absolute_error: 0.1183 - val_loss: 0.0471 - val_mean_absolute_error: 0.1742\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0215 - mean_absolute_error: 0.1139 - val_loss: 0.0482 - val_mean_absolute_error: 0.1754\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0203 - mean_absolute_error: 0.1091 - val_loss: 0.0474 - val_mean_absolute_error: 0.1743\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0194 - mean_absolute_error: 0.1067 - val_loss: 0.0478 - val_mean_absolute_error: 0.1746\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0184 - mean_absolute_error: 0.1023 - val_loss: 0.0486 - val_mean_absolute_error: 0.1758\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0171 - mean_absolute_error: 0.0970 - val_loss: 0.0490 - val_mean_absolute_error: 0.1763\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0167 - mean_absolute_error: 0.0961 - val_loss: 0.0477 - val_mean_absolute_error: 0.1741\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0157 - mean_absolute_error: 0.0919 - val_loss: 0.0507 - val_mean_absolute_error: 0.1787\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0154 - mean_absolute_error: 0.0907 - val_loss: 0.0497 - val_mean_absolute_error: 0.1775\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0147 - mean_absolute_error: 0.0875 - val_loss: 0.0479 - val_mean_absolute_error: 0.1748\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0140 - mean_absolute_error: 0.0855 - val_loss: 0.0495 - val_mean_absolute_error: 0.1776\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0811 - val_loss: 0.0493 - val_mean_absolute_error: 0.1781\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0124 - mean_absolute_error: 0.0790 - val_loss: 0.0526 - val_mean_absolute_error: 0.1834\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0115 - mean_absolute_error: 0.0754 - val_loss: 0.0515 - val_mean_absolute_error: 0.1812\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0114 - mean_absolute_error: 0.0741 - val_loss: 0.0505 - val_mean_absolute_error: 0.1800\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0108 - mean_absolute_error: 0.0724 - val_loss: 0.0506 - val_mean_absolute_error: 0.1802\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0107 - mean_absolute_error: 0.0718 - val_loss: 0.0528 - val_mean_absolute_error: 0.1830\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0105 - mean_absolute_error: 0.0715 - val_loss: 0.0496 - val_mean_absolute_error: 0.1779\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0099 - mean_absolute_error: 0.0682 - val_loss: 0.0507 - val_mean_absolute_error: 0.1808\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0094 - mean_absolute_error: 0.0653 - val_loss: 0.0507 - val_mean_absolute_error: 0.1803\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0088 - mean_absolute_error: 0.0622 - val_loss: 0.0515 - val_mean_absolute_error: 0.1823\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0084 - mean_absolute_error: 0.0608 - val_loss: 0.0513 - val_mean_absolute_error: 0.1819\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0086 - mean_absolute_error: 0.0611 - val_loss: 0.0529 - val_mean_absolute_error: 0.1839\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0080 - mean_absolute_error: 0.0593 - val_loss: 0.0501 - val_mean_absolute_error: 0.1794\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0081 - mean_absolute_error: 0.0594 - val_loss: 0.0496 - val_mean_absolute_error: 0.1792\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0077 - mean_absolute_error: 0.0574 - val_loss: 0.0522 - val_mean_absolute_error: 0.1845\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0076 - mean_absolute_error: 0.0575 - val_loss: 0.0507 - val_mean_absolute_error: 0.1816\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0075 - mean_absolute_error: 0.0560 - val_loss: 0.0520 - val_mean_absolute_error: 0.1831\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0071 - mean_absolute_error: 0.0538 - val_loss: 0.0517 - val_mean_absolute_error: 0.1829\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0069 - mean_absolute_error: 0.0526 - val_loss: 0.0529 - val_mean_absolute_error: 0.1839\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0067 - mean_absolute_error: 0.0513 - val_loss: 0.0531 - val_mean_absolute_error: 0.1846\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0067 - mean_absolute_error: 0.0522 - val_loss: 0.0509 - val_mean_absolute_error: 0.1806\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0062 - mean_absolute_error: 0.0489 - val_loss: 0.0525 - val_mean_absolute_error: 0.1835\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0058 - mean_absolute_error: 0.0469 - val_loss: 0.0515 - val_mean_absolute_error: 0.1826\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0060 - mean_absolute_error: 0.0474 - val_loss: 0.0541 - val_mean_absolute_error: 0.1866\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0057 - mean_absolute_error: 0.0454 - val_loss: 0.0529 - val_mean_absolute_error: 0.1851\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0055 - mean_absolute_error: 0.0444 - val_loss: 0.0513 - val_mean_absolute_error: 0.1832\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0054 - mean_absolute_error: 0.0447 - val_loss: 0.0527 - val_mean_absolute_error: 0.1849\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0053 - mean_absolute_error: 0.0433 - val_loss: 0.0533 - val_mean_absolute_error: 0.1852\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0052 - mean_absolute_error: 0.0425 - val_loss: 0.0519 - val_mean_absolute_error: 0.1835\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0050 - mean_absolute_error: 0.0411 - val_loss: 0.0532 - val_mean_absolute_error: 0.1847\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0050 - mean_absolute_error: 0.0415 - val_loss: 0.0533 - val_mean_absolute_error: 0.1860\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0050 - mean_absolute_error: 0.0414 - val_loss: 0.0537 - val_mean_absolute_error: 0.1851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0048 - mean_absolute_error: 0.0405 - val_loss: 0.0547 - val_mean_absolute_error: 0.1867\n"
     ]
    }
   ],
   "source": [
    "IAN_model_1 = IAN_model_1.fit(x=trainX,y=trainY, epochs=50,batch_size=64,validation_data=(testX,testY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'>\n",
    "After 50 epochs:\n",
    " loss: 0.0048 - mean_absolute_error: 0.0405 - val_loss: 0.0547 - val_mean_absolute_error: 0.1867\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model2(dropout,learning_rate,em,em_dim,lstm_out, n_hidden_layer,em_trainable_flag,n_filters=150):\n",
    "   \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    \n",
    "    c=Dropout(0.5)(context)\n",
    "    \n",
    "    c=Conv1D(n_filters,kernel_size=3,activation='relu')(context)\n",
    "    \n",
    "    m = Bidirectional(LSTM(150,return_sequences=False,recurrent_dropout=dropout))(c)\n",
    "    \n",
    "    #a=  Attention()(m)\n",
    "                   \n",
    "    a=Dense(400,activation='relu')(m)\n",
    "        \n",
    "    out=Dense(1,activation='sigmoid')(a)\n",
    "    \n",
    "    model= Model(inputs=input_context ,outputs=out)\n",
    "    \n",
    "\n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Context (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "embedding_37 (Embedding)     (None, 11, 300)           997200    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 9, 150)            135150    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 300)               361200    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,614,351\n",
      "Trainable params: 617,151\n",
      "Non-trainable params: 997,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn_model_1 = define_model2(dropout=0.2,\n",
    "                     learning_rate=0.01,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0415 - mean_absolute_error: 0.1799 - val_loss: 0.0465 - val_mean_absolute_error: 0.1793\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0399 - mean_absolute_error: 0.1728 - val_loss: 0.0461 - val_mean_absolute_error: 0.1790\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0393 - mean_absolute_error: 0.1707 - val_loss: 0.0464 - val_mean_absolute_error: 0.1785\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0386 - mean_absolute_error: 0.1709 - val_loss: 0.0465 - val_mean_absolute_error: 0.1780\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0376 - mean_absolute_error: 0.1662 - val_loss: 0.0461 - val_mean_absolute_error: 0.1774\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0363 - mean_absolute_error: 0.1651 - val_loss: 0.0475 - val_mean_absolute_error: 0.1775\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0340 - mean_absolute_error: 0.1590 - val_loss: 0.0473 - val_mean_absolute_error: 0.1771\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0308 - mean_absolute_error: 0.1495 - val_loss: 0.0490 - val_mean_absolute_error: 0.1786\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0267 - mean_absolute_error: 0.1357 - val_loss: 0.0490 - val_mean_absolute_error: 0.1785\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0229 - mean_absolute_error: 0.1215 - val_loss: 0.0518 - val_mean_absolute_error: 0.1825\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0192 - mean_absolute_error: 0.1090 - val_loss: 0.0509 - val_mean_absolute_error: 0.1812\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0168 - mean_absolute_error: 0.1014 - val_loss: 0.0496 - val_mean_absolute_error: 0.1787\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0142 - mean_absolute_error: 0.0920 - val_loss: 0.0503 - val_mean_absolute_error: 0.1789\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0128 - mean_absolute_error: 0.0867 - val_loss: 0.0489 - val_mean_absolute_error: 0.1771\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0100 - mean_absolute_error: 0.0765 - val_loss: 0.0509 - val_mean_absolute_error: 0.1795\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0733 - val_loss: 0.0517 - val_mean_absolute_error: 0.1810\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0076 - mean_absolute_error: 0.0667 - val_loss: 0.0516 - val_mean_absolute_error: 0.1801\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0066 - mean_absolute_error: 0.0623 - val_loss: 0.0502 - val_mean_absolute_error: 0.1774\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0057 - mean_absolute_error: 0.0576 - val_loss: 0.0514 - val_mean_absolute_error: 0.1796\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0052 - mean_absolute_error: 0.0539 - val_loss: 0.0511 - val_mean_absolute_error: 0.1791\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0045 - mean_absolute_error: 0.0502 - val_loss: 0.0498 - val_mean_absolute_error: 0.1769\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0040 - mean_absolute_error: 0.0484 - val_loss: 0.0494 - val_mean_absolute_error: 0.1767\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0037 - mean_absolute_error: 0.0442 - val_loss: 0.0514 - val_mean_absolute_error: 0.1798\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0035 - mean_absolute_error: 0.0439 - val_loss: 0.0505 - val_mean_absolute_error: 0.1781\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0033 - mean_absolute_error: 0.0423 - val_loss: 0.0536 - val_mean_absolute_error: 0.1827\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0029 - mean_absolute_error: 0.0390 - val_loss: 0.0535 - val_mean_absolute_error: 0.1825\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0027 - mean_absolute_error: 0.0375 - val_loss: 0.0529 - val_mean_absolute_error: 0.1814\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0024 - mean_absolute_error: 0.0359 - val_loss: 0.0516 - val_mean_absolute_error: 0.1788\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0024 - mean_absolute_error: 0.0338 - val_loss: 0.0497 - val_mean_absolute_error: 0.1759\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0025 - mean_absolute_error: 0.0356 - val_loss: 0.0511 - val_mean_absolute_error: 0.1782\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0022 - mean_absolute_error: 0.0335 - val_loss: 0.0528 - val_mean_absolute_error: 0.1812\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0021 - mean_absolute_error: 0.0318 - val_loss: 0.0517 - val_mean_absolute_error: 0.1791\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0019 - mean_absolute_error: 0.0304 - val_loss: 0.0522 - val_mean_absolute_error: 0.1797\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0018 - mean_absolute_error: 0.0293 - val_loss: 0.0512 - val_mean_absolute_error: 0.1779\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0018 - mean_absolute_error: 0.0286 - val_loss: 0.0508 - val_mean_absolute_error: 0.1775\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0017 - mean_absolute_error: 0.0288 - val_loss: 0.0521 - val_mean_absolute_error: 0.1797\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0018 - mean_absolute_error: 0.0290 - val_loss: 0.0553 - val_mean_absolute_error: 0.1857\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0016 - mean_absolute_error: 0.0277 - val_loss: 0.0545 - val_mean_absolute_error: 0.1842\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0018 - mean_absolute_error: 0.0292 - val_loss: 0.0524 - val_mean_absolute_error: 0.1801\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0019 - mean_absolute_error: 0.0315 - val_loss: 0.0569 - val_mean_absolute_error: 0.1887\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0016 - mean_absolute_error: 0.0282 - val_loss: 0.0522 - val_mean_absolute_error: 0.1800\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0014 - mean_absolute_error: 0.0255 - val_loss: 0.0507 - val_mean_absolute_error: 0.1768\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0013 - mean_absolute_error: 0.0248 - val_loss: 0.0513 - val_mean_absolute_error: 0.1780\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0013 - mean_absolute_error: 0.0240 - val_loss: 0.0529 - val_mean_absolute_error: 0.1805\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0012 - mean_absolute_error: 0.0221 - val_loss: 0.0527 - val_mean_absolute_error: 0.1806\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0013 - mean_absolute_error: 0.0244 - val_loss: 0.0527 - val_mean_absolute_error: 0.1806\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0012 - mean_absolute_error: 0.0227 - val_loss: 0.0549 - val_mean_absolute_error: 0.1848\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0013 - mean_absolute_error: 0.0244 - val_loss: 0.0514 - val_mean_absolute_error: 0.1776\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0012 - mean_absolute_error: 0.0219 - val_loss: 0.0526 - val_mean_absolute_error: 0.1804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0011 - mean_absolute_error: 0.0210 - val_loss: 0.0539 - val_mean_absolute_error: 0.1829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fca8bdc1d0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_1.fit(x=input_context,y=trainY, epochs=50,batch_size=64,validation_data=(v_sentence,v_sentiment))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relu and sigmoid : <font color='red'>\n",
    "After 50 epochs:\n",
    "    loss: 0.0011 - mean_absolute_error: 0.0210 - val_loss: 0.0539 - val_mean_absolute_error: 0.1829\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN +LSTM +ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model3(dropout,learning_rate,em,em_dim,lstm_out, n_hidden_layer,em_trainable_flag,n_filters=150):\n",
    "   \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    \n",
    "    c=Dropout(0.5)(context)\n",
    "    \n",
    "    c=Conv1D(n_filters,kernel_size=3,activation='relu')(context)\n",
    "    \n",
    "    m = Bidirectional(LSTM(150,return_sequences=True,recurrent_dropout=dropout))(c)\n",
    "    \n",
    "    a=  Attention()(m)\n",
    "                   \n",
    "    a=Dense(400,activation='relu')(a)\n",
    "        \n",
    "    out=Dense(1,activation='sigmoid')(a)\n",
    "    \n",
    "    model= Model(inputs=input_context ,outputs=out)\n",
    "    \n",
    "\n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Context (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 11, 300)           997200    \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 9, 150)            135150    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 9, 300)            361200    \n",
      "_________________________________________________________________\n",
      "attention_4 (Attention)      (None, 300)               309       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,614,660\n",
      "Trainable params: 617,460\n",
      "Non-trainable params: 997,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn_model_3 = define_model3(dropout=0.2,\n",
    "                     learning_rate=0.01,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 3s 3ms/step - loss: 0.0416 - mean_absolute_error: 0.1813 - val_loss: 0.0459 - val_mean_absolute_error: 0.1795\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0400 - mean_absolute_error: 0.1735 - val_loss: 0.0461 - val_mean_absolute_error: 0.1793\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0396 - mean_absolute_error: 0.1728 - val_loss: 0.0461 - val_mean_absolute_error: 0.1792\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0392 - mean_absolute_error: 0.1715 - val_loss: 0.0462 - val_mean_absolute_error: 0.1791\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0385 - mean_absolute_error: 0.1701 - val_loss: 0.0461 - val_mean_absolute_error: 0.1787\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0374 - mean_absolute_error: 0.1678 - val_loss: 0.0464 - val_mean_absolute_error: 0.1781\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0357 - mean_absolute_error: 0.1625 - val_loss: 0.0459 - val_mean_absolute_error: 0.1772\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0329 - mean_absolute_error: 0.1549 - val_loss: 0.0469 - val_mean_absolute_error: 0.1774\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0288 - mean_absolute_error: 0.1425 - val_loss: 0.0466 - val_mean_absolute_error: 0.1761\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0250 - mean_absolute_error: 0.1281 - val_loss: 0.0495 - val_mean_absolute_error: 0.1799\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0214 - mean_absolute_error: 0.1159 - val_loss: 0.0507 - val_mean_absolute_error: 0.1823\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.1077 - val_loss: 0.0534 - val_mean_absolute_error: 0.1864\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0168 - mean_absolute_error: 0.1009 - val_loss: 0.0459 - val_mean_absolute_error: 0.1735\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0143 - mean_absolute_error: 0.0914 - val_loss: 0.0478 - val_mean_absolute_error: 0.1762\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0129 - mean_absolute_error: 0.0888 - val_loss: 0.0536 - val_mean_absolute_error: 0.1864\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0112 - mean_absolute_error: 0.0812 - val_loss: 0.0493 - val_mean_absolute_error: 0.1785\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0095 - mean_absolute_error: 0.0731 - val_loss: 0.0493 - val_mean_absolute_error: 0.1781\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0679 - val_loss: 0.0500 - val_mean_absolute_error: 0.1790\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0073 - mean_absolute_error: 0.0642 - val_loss: 0.0514 - val_mean_absolute_error: 0.1816\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0066 - mean_absolute_error: 0.0608 - val_loss: 0.0512 - val_mean_absolute_error: 0.1809\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0059 - mean_absolute_error: 0.0570 - val_loss: 0.0533 - val_mean_absolute_error: 0.1837\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0533 - val_loss: 0.0557 - val_mean_absolute_error: 0.1875\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0519 - val_loss: 0.0548 - val_mean_absolute_error: 0.1861\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0041 - mean_absolute_error: 0.0478 - val_loss: 0.0518 - val_mean_absolute_error: 0.1805\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0039 - mean_absolute_error: 0.0452 - val_loss: 0.0505 - val_mean_absolute_error: 0.1778\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0037 - mean_absolute_error: 0.0446 - val_loss: 0.0506 - val_mean_absolute_error: 0.1782\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0034 - mean_absolute_error: 0.0419 - val_loss: 0.0501 - val_mean_absolute_error: 0.1772\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0033 - mean_absolute_error: 0.0425 - val_loss: 0.0531 - val_mean_absolute_error: 0.1820\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0030 - mean_absolute_error: 0.0391 - val_loss: 0.0543 - val_mean_absolute_error: 0.1847\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0399 - val_loss: 0.0532 - val_mean_absolute_error: 0.1819\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0352 - val_loss: 0.0545 - val_mean_absolute_error: 0.1842\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0362 - val_loss: 0.0555 - val_mean_absolute_error: 0.1865\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0023 - mean_absolute_error: 0.0345 - val_loss: 0.0552 - val_mean_absolute_error: 0.1860\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0022 - mean_absolute_error: 0.0331 - val_loss: 0.0547 - val_mean_absolute_error: 0.1852\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0021 - mean_absolute_error: 0.0326 - val_loss: 0.0527 - val_mean_absolute_error: 0.1810\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0019 - mean_absolute_error: 0.0303 - val_loss: 0.0521 - val_mean_absolute_error: 0.1795\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0019 - mean_absolute_error: 0.0307 - val_loss: 0.0527 - val_mean_absolute_error: 0.1808\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0018 - mean_absolute_error: 0.0297 - val_loss: 0.0536 - val_mean_absolute_error: 0.1823\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0018 - mean_absolute_error: 0.0284 - val_loss: 0.0527 - val_mean_absolute_error: 0.1805\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0017 - mean_absolute_error: 0.0280 - val_loss: 0.0528 - val_mean_absolute_error: 0.1803\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0016 - mean_absolute_error: 0.0274 - val_loss: 0.0529 - val_mean_absolute_error: 0.1807\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0017 - mean_absolute_error: 0.0286 - val_loss: 0.0552 - val_mean_absolute_error: 0.1846\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0016 - mean_absolute_error: 0.0277 - val_loss: 0.0560 - val_mean_absolute_error: 0.1860\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0017 - mean_absolute_error: 0.0277 - val_loss: 0.0522 - val_mean_absolute_error: 0.1795\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0018 - mean_absolute_error: 0.0284 - val_loss: 0.0520 - val_mean_absolute_error: 0.1792\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0016 - mean_absolute_error: 0.0272 - val_loss: 0.0519 - val_mean_absolute_error: 0.1783\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0016 - mean_absolute_error: 0.0269 - val_loss: 0.0536 - val_mean_absolute_error: 0.1811\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0014 - mean_absolute_error: 0.0253 - val_loss: 0.0527 - val_mean_absolute_error: 0.1803\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0014 - mean_absolute_error: 0.0244 - val_loss: 0.0538 - val_mean_absolute_error: 0.1825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0013 - mean_absolute_error: 0.0234 - val_loss: 0.0536 - val_mean_absolute_error: 0.1818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bc4e04d68>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_3.fit(x=input_context,y=trainY, epochs=50,batch_size=64,validation_data=(v_sentence,v_sentiment))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 epochs : loss: 0.0013 - mean_absolute_error: 0.0234 - val_loss: 0.0536 - val_mean_absolute_error: 0.1818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CHANNEL CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model2(dropout,learning_rate,em,em_dim,em_trainable_flag,n_filters=100):\n",
    "    \n",
    "\n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    inputs1= embedding(input_context)\n",
    "    \n",
    "    \n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=3, activation='relu')(inputs1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=4, activation='relu')(inputs1)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=5, activation='relu')(inputs1)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    conv4 = Conv1D(filters=n_filters, kernel_size=2, activation='relu')(inputs1)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    pool4 = MaxPooling1D(pool_size=2)(drop4)\n",
    "    flat4 = Flatten()(pool4)\n",
    "    \n",
    "    conv5 = Conv1D(filters=n_filters, kernel_size=6, activation='relu')(inputs1)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "    pool5 = MaxPooling1D(pool_size=2)(drop5)\n",
    "    flat5 = Flatten()(pool5)\n",
    "    # merge\n",
    "    \n",
    "    merged = concatenate([flat1, flat2, flat3,flat4,flat5])\n",
    "    # interpretation\n",
    "    dense1 = Dense(400, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=input_context, outputs=outputs)\n",
    "    \n",
    "    # compile\n",
    "    \n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_2 = cnn_model2(dropout=0.5,\n",
    "                     learning_rate=0.001,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1173 samples, validate on 192 samples\n",
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 2s 1ms/step - loss: 0.0441 - mean_absolute_error: 0.1794 - val_loss: 0.0472 - val_mean_absolute_error: 0.1807\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 1s 962us/step - loss: 0.0380 - mean_absolute_error: 0.1667 - val_loss: 0.0481 - val_mean_absolute_error: 0.1798\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 1s 944us/step - loss: 0.0348 - mean_absolute_error: 0.1592 - val_loss: 0.0468 - val_mean_absolute_error: 0.1783\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 1s 973us/step - loss: 0.0311 - mean_absolute_error: 0.1488 - val_loss: 0.0467 - val_mean_absolute_error: 0.1777\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 1s 942us/step - loss: 0.0281 - mean_absolute_error: 0.1408 - val_loss: 0.0468 - val_mean_absolute_error: 0.1771\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 1s 971us/step - loss: 0.0259 - mean_absolute_error: 0.1341 - val_loss: 0.0472 - val_mean_absolute_error: 0.1769\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 1s 939us/step - loss: 0.0238 - mean_absolute_error: 0.1255 - val_loss: 0.0481 - val_mean_absolute_error: 0.1765\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 1s 979us/step - loss: 0.0217 - mean_absolute_error: 0.1203 - val_loss: 0.0477 - val_mean_absolute_error: 0.1756\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 1s 940us/step - loss: 0.0195 - mean_absolute_error: 0.1128 - val_loss: 0.0487 - val_mean_absolute_error: 0.1769\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 1s 942us/step - loss: 0.0182 - mean_absolute_error: 0.1089 - val_loss: 0.0467 - val_mean_absolute_error: 0.1735\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 1s 940us/step - loss: 0.0158 - mean_absolute_error: 0.1015 - val_loss: 0.0494 - val_mean_absolute_error: 0.1768\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 1s 928us/step - loss: 0.0145 - mean_absolute_error: 0.0956 - val_loss: 0.0497 - val_mean_absolute_error: 0.1774\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 1s 910us/step - loss: 0.0136 - mean_absolute_error: 0.0926 - val_loss: 0.0471 - val_mean_absolute_error: 0.1739\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 1s 921us/step - loss: 0.0130 - mean_absolute_error: 0.0905 - val_loss: 0.0488 - val_mean_absolute_error: 0.1760\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 1s 914us/step - loss: 0.0118 - mean_absolute_error: 0.0848 - val_loss: 0.0467 - val_mean_absolute_error: 0.1728\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 1s 914us/step - loss: 0.0110 - mean_absolute_error: 0.0820 - val_loss: 0.0475 - val_mean_absolute_error: 0.1740\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 1s 911us/step - loss: 0.0101 - mean_absolute_error: 0.0788 - val_loss: 0.0495 - val_mean_absolute_error: 0.1761\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 1s 899us/step - loss: 0.0099 - mean_absolute_error: 0.0765 - val_loss: 0.0486 - val_mean_absolute_error: 0.1743\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 1s 959us/step - loss: 0.0090 - mean_absolute_error: 0.0744 - val_loss: 0.0485 - val_mean_absolute_error: 0.1744\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 1s 998us/step - loss: 0.0089 - mean_absolute_error: 0.0739 - val_loss: 0.0517 - val_mean_absolute_error: 0.1788\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 1s 935us/step - loss: 0.0085 - mean_absolute_error: 0.0713 - val_loss: 0.0472 - val_mean_absolute_error: 0.1722\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 1s 917us/step - loss: 0.0077 - mean_absolute_error: 0.0677 - val_loss: 0.0476 - val_mean_absolute_error: 0.1727\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 1s 918us/step - loss: 0.0082 - mean_absolute_error: 0.0713 - val_loss: 0.0501 - val_mean_absolute_error: 0.1762\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 1s 989us/step - loss: 0.0072 - mean_absolute_error: 0.0660 - val_loss: 0.0497 - val_mean_absolute_error: 0.1755\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 1s 970us/step - loss: 0.0074 - mean_absolute_error: 0.0663 - val_loss: 0.0488 - val_mean_absolute_error: 0.1741\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 1s 994us/step - loss: 0.0069 - mean_absolute_error: 0.0661 - val_loss: 0.0477 - val_mean_absolute_error: 0.1716\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 1s 960us/step - loss: 0.0063 - mean_absolute_error: 0.0625 - val_loss: 0.0487 - val_mean_absolute_error: 0.1731\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 1s 939us/step - loss: 0.0069 - mean_absolute_error: 0.0646 - val_loss: 0.0479 - val_mean_absolute_error: 0.1721\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 1s 983us/step - loss: 0.0063 - mean_absolute_error: 0.0617 - val_loss: 0.0485 - val_mean_absolute_error: 0.1731\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 1s 992us/step - loss: 0.0060 - mean_absolute_error: 0.0604 - val_loss: 0.0466 - val_mean_absolute_error: 0.1695\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 1s 987us/step - loss: 0.0059 - mean_absolute_error: 0.0596 - val_loss: 0.0487 - val_mean_absolute_error: 0.1728\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0572 - val_loss: 0.0491 - val_mean_absolute_error: 0.1733\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0051 - mean_absolute_error: 0.0557 - val_loss: 0.0491 - val_mean_absolute_error: 0.1735\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0564 - val_loss: 0.0482 - val_mean_absolute_error: 0.1720\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 1s 941us/step - loss: 0.0052 - mean_absolute_error: 0.0552 - val_loss: 0.0479 - val_mean_absolute_error: 0.1714\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 1s 906us/step - loss: 0.0049 - mean_absolute_error: 0.0544 - val_loss: 0.0475 - val_mean_absolute_error: 0.1706\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 1s 905us/step - loss: 0.0052 - mean_absolute_error: 0.0555 - val_loss: 0.0506 - val_mean_absolute_error: 0.1759\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 1s 964us/step - loss: 0.0050 - mean_absolute_error: 0.0546 - val_loss: 0.0481 - val_mean_absolute_error: 0.1721\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 1s 972us/step - loss: 0.0050 - mean_absolute_error: 0.0547 - val_loss: 0.0513 - val_mean_absolute_error: 0.1773\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 1s 877us/step - loss: 0.0047 - mean_absolute_error: 0.0538 - val_loss: 0.0492 - val_mean_absolute_error: 0.1738\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 1s 896us/step - loss: 0.0043 - mean_absolute_error: 0.0507 - val_loss: 0.0499 - val_mean_absolute_error: 0.1750\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 1s 905us/step - loss: 0.0045 - mean_absolute_error: 0.0512 - val_loss: 0.0515 - val_mean_absolute_error: 0.1773\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0503 - val_loss: 0.0512 - val_mean_absolute_error: 0.1764\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0511 - val_loss: 0.0474 - val_mean_absolute_error: 0.1712\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0042 - mean_absolute_error: 0.0501 - val_loss: 0.0481 - val_mean_absolute_error: 0.1718\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0039 - mean_absolute_error: 0.0486 - val_loss: 0.0486 - val_mean_absolute_error: 0.1721\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0038 - mean_absolute_error: 0.0476 - val_loss: 0.0488 - val_mean_absolute_error: 0.1724\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0039 - mean_absolute_error: 0.0481 - val_loss: 0.0483 - val_mean_absolute_error: 0.1722\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0038 - mean_absolute_error: 0.0479 - val_loss: 0.0500 - val_mean_absolute_error: 0.1742\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0040 - mean_absolute_error: 0.0488 - val_loss: 0.0497 - val_mean_absolute_error: 0.1733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bb2e249e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_2.fit(x=input_context,y=trainY, epochs=50,batch_size=64,validation_data=(v_sentence,v_sentiment))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "After 50 epochs:\n",
    "    loss: 0.0040 - mean_absolute_error: 0.0488 - val_loss: 0.0497 - val_mean_absolute_error: 0.1733\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASPECT MODELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes=27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag,em_dim):\n",
    "     \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(max_length,),name='Target')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    v_target = embedding(input_target)\n",
    "    \n",
    "    print(\"Target\" ,v_target.shape)\n",
    "    \n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(context)\n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(H)\n",
    "    H_all, H_last , _ = LSTM (lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"AT\")(H)\n",
    "    \n",
    "    concat = concatenate(inputs =[v_target,H_all])\n",
    "    print(\"Concat\",concat.shape)\n",
    "    \n",
    "    r=AttentionWithContext(name='Attention')([H_all,concat])\n",
    "    \n",
    "    pooling= GlobalAveragePooling1D()(H_all)\n",
    "    \n",
    "    out=Final2(name='Final')([r , pooling])\n",
    "    \n",
    "    out=Dense(int((2*lstm_out+27)/2),activation='relu')(out)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(out)\n",
    "    \n",
    "    AT_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    AT_model.compile(loss = 'categorical_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    print(AT_model.summary())\n",
    "    \n",
    "    return AT_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (?, 11, 300)\n",
      "Concat (?, 11, 600)\n",
      "M1 (?, 11, 600)\n",
      "M (?, 11, 1)\n",
      "alpha (?, 11, 1)\n",
      "r (?, 300)\n",
      "H_all (?, 300)\n",
      "m2.shape (?, 300)\n",
      "m1  (?, 300)\n",
      "(?, 300) h_final\n",
      "OUT (?, 27)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 11, 300)      997200      Context[0][0]                    \n",
      "                                                                 Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_52 (LSTM)                  (None, 11, 300)      721200      embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_53 (LSTM)                  (None, 11, 300)      721200      lstm_52[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Target (InputLayer)             (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "AT (LSTM)                       [(None, 11, 300), (N 721200      lstm_53[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 11, 600)      0           embedding_28[1][0]               \n",
      "                                                                 AT[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "Attention (AttentionWithContext (300, 1)             360600      AT[0][0]                         \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 300)          0           AT[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "Final (Final2)                  (None, 27)           188127      Attention[0][0]                  \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 313)          8764        Final[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 27)           8478        dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,726,769\n",
      "Trainable params: 2,729,569\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "At_model = define_model(learning_rate=0.00069,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 22s 19ms/step - loss: 2.8569 - acc: 0.3478\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 2.4569 - acc: 0.3725\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 2.3666 - acc: 0.3751\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 2.3366 - acc: 0.3819\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 12s 11ms/step - loss: 2.2396 - acc: 0.3845\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 2.1441 - acc: 0.4160\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 2.0165 - acc: 0.4348\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.9025 - acc: 0.4638\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.8038 - acc: 0.4962\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 1.6637 - acc: 0.5320\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 1.5630 - acc: 0.5635\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 1.5118 - acc: 0.5720\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.4134 - acc: 0.5942\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.3146 - acc: 0.6317\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.2835 - acc: 0.6257\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.1811 - acc: 0.6624\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.0820 - acc: 0.6846\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.0458 - acc: 0.6837\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.0275 - acc: 0.6957\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 12s 11ms/step - loss: 0.9397 - acc: 0.7272\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 0.8666 - acc: 0.7391\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.7737 - acc: 0.7639\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.7452 - acc: 0.7707\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.6829 - acc: 0.7860\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.6378 - acc: 0.8005\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.5692 - acc: 0.8124\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.5288 - acc: 0.8193\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.5742 - acc: 0.8176\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.5856 - acc: 0.8039\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.4788 - acc: 0.8440\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.4679 - acc: 0.8440\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 12s 11ms/step - loss: 0.4020 - acc: 0.8662\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 0.3440 - acc: 0.8858\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.3441 - acc: 0.8968\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.2616 - acc: 0.9122\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 0.2612 - acc: 0.9113\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.3597 - acc: 0.8806\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 12s 11ms/step - loss: 0.2871 - acc: 0.9020\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.2685 - acc: 0.9105\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 0.2228 - acc: 0.9233\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.2735 - acc: 0.9301\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.3306 - acc: 0.8832\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.2086 - acc: 0.9361\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.1276 - acc: 0.9633\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1324 - acc: 0.9599\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1391 - acc: 0.9548\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1118 - acc: 0.9608\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1417 - acc: 0.9608\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1103 - acc: 0.9625\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1233 - acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "Aspect_model = At_model.fit(x=trainX,y=aspect, epochs=50,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 epochs : loss: 0.1233 - acc: 0.9625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Attention + bidirectional LSTM (Adding Attention to our model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_1(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag,em_dim):\n",
    "     \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "        \n",
    "    a = Bidirectional(LSTM(300, return_sequences=True,recurrent_dropout=dropout))(context)\n",
    "    \n",
    "    print(a.shape)\n",
    "\n",
    "    alpha = Attention()(a)\n",
    "    \n",
    "    x=Dense(int((2*lstm_out+27)/2),activation='relu')(alpha)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(x)\n",
    "    \n",
    "    model= Model(inputs=input_context ,outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 600)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Context (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 11, 300)           997200    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 11, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "attention_3 (Attention)      (None, 600)               611       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 313)               188113    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 27)                8478      \n",
      "=================================================================\n",
      "Total params: 2,636,802\n",
      "Trainable params: 1,639,602\n",
      "Non-trainable params: 997,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Aspect_model_1 = define_model_1(learning_rate=0.00069,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 12s 10ms/step - loss: 2.8559 - acc: 0.3495\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 2.4349 - acc: 0.3725\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 2.2613 - acc: 0.3896\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 2.0446 - acc: 0.4408\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.8361 - acc: 0.4962\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.6395 - acc: 0.5388\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.4278 - acc: 0.5899\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.3024 - acc: 0.6257\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.1509 - acc: 0.6743\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.0441 - acc: 0.6965\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.8970 - acc: 0.7460\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.7847 - acc: 0.7681\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.6772 - acc: 0.8005\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.6248 - acc: 0.8176\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.5625 - acc: 0.8278\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.4755 - acc: 0.8508\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.4222 - acc: 0.8875\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.3806 - acc: 0.8909\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.3366 - acc: 0.9054\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.3160 - acc: 0.9045\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.2533 - acc: 0.9309\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.2246 - acc: 0.9309\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.1774 - acc: 0.9548\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.1626 - acc: 0.9625\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.1638 - acc: 0.9582\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.1394 - acc: 0.9659\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.1179 - acc: 0.9668\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0985 - acc: 0.9787\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.1046 - acc: 0.9736\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0923 - acc: 0.9770\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.0782 - acc: 0.9829\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0831 - acc: 0.9838\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0777 - acc: 0.9821\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0645 - acc: 0.9847\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0748 - acc: 0.9795\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0671 - acc: 0.9847\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.0619 - acc: 0.9864\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0668 - acc: 0.9829\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0563 - acc: 0.9864\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0469 - acc: 0.9906\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0494 - acc: 0.9898\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0403 - acc: 0.9932\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 6s 6ms/step - loss: 0.0482 - acc: 0.9881\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0490 - acc: 0.9855\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0441 - acc: 0.9864\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0544 - acc: 0.9804\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0567 - acc: 0.9838\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 7s 6ms/step - loss: 0.0554 - acc: 0.9847\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 8s 6ms/step - loss: 0.0584 - acc: 0.9847\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 9s 7ms/step - loss: 0.0416 - acc: 0.9889\n"
     ]
    }
   ],
   "source": [
    "Aspect_model = Aspect_model_1.fit(x=input_context,y=aspect, epochs=50,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>\n",
    " After 50 epochs: loss: 0.0416 - acc: 0.9889\n",
    "  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ATAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_ATAE(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag, em_dim):\n",
    "    \n",
    "    \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(max_length,),name='Target')\n",
    "  \n",
    "   \n",
    "    #print(input_target.shape)\n",
    "    #print(input_context.shape)\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    v_target = embedding(input_target)\n",
    "    \n",
    "    #print(context.shape)\n",
    "    print(\"Target\" ,v_target.shape)\n",
    "\n",
    "    \n",
    "    concat = concatenate(inputs =[v_target,context])\n",
    "    print(concat.shape)\n",
    "    inputs = Dropout(dropout)(concat)\n",
    "    print(inputs.shape)   \n",
    "    \n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(inputs)\n",
    "    H = LSTM (lstm_out, recurrent_dropout=dropout,return_sequences=True)(H)\n",
    "    H_all, H_last , _ = LSTM (lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"ATAE\")(H)\n",
    "    \n",
    "    concat = concatenate(inputs =[v_target,H_all])\n",
    "    print(\"Concat\",concat.shape)\n",
    "    \n",
    "    r=AttentionWithContext(name='Attention')([H_all,concat])\n",
    "    \n",
    "    pooling= GlobalAveragePooling1D()(H_all)\n",
    "    \n",
    "    out=Final2(name='Final')([r , pooling])\n",
    "    \n",
    "    #out=Dense(int((2*lstm_out+27)/2),activation='relu')(out)\n",
    "    \n",
    "    out= Activation('tanh')(out)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(out)\n",
    "    \n",
    "    ATAE_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    ATAE_model.compile(loss = 'categorical_crossentropy', optimizer=optimizer,metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    print(ATAE_model.summary())\n",
    "    \n",
    "    return ATAE_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (?, 11, 300)\n",
      "(?, 11, 600)\n",
      "(?, 11, 600)\n",
      "Concat (?, 11, 600)\n",
      "M1 (?, 11, 600)\n",
      "M (?, 11, 1)\n",
      "alpha (?, 11, 1)\n",
      "r (?, 300)\n",
      "H_all (?, 300)\n",
      "m2.shape (?, 300)\n",
      "m1  (?, 300)\n",
      "(?, 300) h_final\n",
      "OUT (?, 27)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Target (InputLayer)             (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 11, 300)      997200      Context[0][0]                    \n",
      "                                                                 Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 11, 600)      0           embedding_31[1][0]               \n",
      "                                                                 embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 11, 600)      0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_58 (LSTM)                  (None, 11, 300)      1081200     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_59 (LSTM)                  (None, 11, 300)      721200      lstm_58[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ATAE (LSTM)                     [(None, 11, 300), (N 721200      lstm_59[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 11, 600)      0           embedding_31[1][0]               \n",
      "                                                                 ATAE[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Attention (AttentionWithContext (300, 1)             360600      ATAE[0][0]                       \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 300)          0           ATAE[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Final (Final2)                  (None, 27)           188127      Attention[0][0]                  \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 27)           0           Final[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 27)           756         activation_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,070,283\n",
      "Trainable params: 3,073,083\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ATAE_model =Model_ATAE(learning_rate=0.00069,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 30s 26ms/step - loss: 2.8263 - acc: 0.3512\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 18s 16ms/step - loss: 2.4954 - acc: 0.3734\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 19s 16ms/step - loss: 2.3471 - acc: 0.3939\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 19s 16ms/step - loss: 2.1848 - acc: 0.4246\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 19s 16ms/step - loss: 2.0342 - acc: 0.4757\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 19s 16ms/step - loss: 1.9132 - acc: 0.5038\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 19s 16ms/step - loss: 1.8269 - acc: 0.5200\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 18s 16ms/step - loss: 1.7552 - acc: 0.5362\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 1.6784 - acc: 0.5482\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.5979 - acc: 0.5908\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 1.6023 - acc: 0.5754\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.4957 - acc: 0.6002\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 1.4641 - acc: 0.6172\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.4501 - acc: 0.6215\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 18s 16ms/step - loss: 1.3969 - acc: 0.6419\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 1.3208 - acc: 0.6667\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.3277 - acc: 0.6496\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.2266 - acc: 0.6743\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 1.2095 - acc: 0.6709\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.2029 - acc: 0.6718\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.1424 - acc: 0.6974\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.1383 - acc: 0.6948\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 1.0980 - acc: 0.7118\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.0525 - acc: 0.7118\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 17s 15ms/step - loss: 1.0457 - acc: 0.7221\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 1.0125 - acc: 0.7272\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 0.9581 - acc: 0.7468\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 18s 16ms/step - loss: 0.9504 - acc: 0.7562\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 18s 15ms/step - loss: 0.8894 - acc: 0.7579\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 18s 16ms/step - loss: 0.8825 - acc: 0.7587\n",
      "Epoch 31/50\n",
      "  64/1173 [>.............................] - ETA: 17s - loss: 0.9919 - acc: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-25625481193e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAspect_model_3\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mATAE_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Aspect_model_3= ATAE_model.fit(x=trainX,y=aspect, epochs=50,batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After  30 epochs : loss: 0.7511 - acc: 0.7630  relu and no tanh after final layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Model_IAN_1_aspect(learning_rate,dropout,lstm_out,n_hidden_layer,em,em_trainable_flag, em_dim):\n",
    "    \n",
    "    input_context = Input(shape=(max_length,),name='Context')\n",
    "    input_target = Input(shape=(11,),name='Target')\n",
    "    \n",
    "    print(\"Target \",input_target.shape)\n",
    "    print(\"Context\" ,input_context.shape)\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "\n",
    "    context=embedding(input_context)\n",
    "    target= embedding(input_target)\n",
    "    print(\"Target_embedding\",target.shape)\n",
    "    print(\"Context_embedding\", context.shape)\n",
    " \n",
    "    H_c , _ , _ = LSTM( lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"LSTM_C\")(context)\n",
    "    H_t , _ , _ = LSTM( lstm_out, recurrent_dropout=dropout,return_state=True,return_sequences=True,name=\"LSTM_T\")(target)\n",
    "\n",
    "    print(\"hc\", H_c.shape)\n",
    "    print(\"ht\",H_t.shape)\n",
    "    \n",
    "    c_avg = GlobalAveragePooling1D(name='POOL_C')(H_c)  \n",
    "    t_avg = GlobalAveragePooling1D(name='POOL_T')(H_t)\n",
    "    \n",
    "    print(\"C_AVG\", c_avg.shape)\n",
    "    print(\"t_avg\",t_avg.shape)\n",
    "    \n",
    "\n",
    "    c_r = Lambda(lambda x: one_step_attention(x[0],x[1],11))([H_c,t_avg])\n",
    "    t_r = Lambda(lambda x: one_step_attention(x[0],x[1],11))([H_t,c_avg])\n",
    "    \n",
    "    print(\"c_r\",c_r.shape)\n",
    "    print(\"t_r\",t_r.shape)\n",
    "   \n",
    "    d = concatenate(inputs=[c_r , t_r])\n",
    "    \n",
    "    print(\"d\",d.shape)\n",
    "    \n",
    "    x=Dense(int((2*lstm_out+27)/2),activation='relu')(d)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(x)\n",
    "   \n",
    "    IAN_model= Model(inputs=[input_context,input_target],outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    IAN_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    print( IAN_model.summary())\n",
    "    \n",
    "    return  IAN_model\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target  (?, 11)\n",
      "Context (?, 11)\n",
      "Target_embedding (?, 11, 300)\n",
      "Context_embedding (?, 11, 300)\n",
      "hc (?, ?, 300)\n",
      "ht (?, ?, 300)\n",
      "C_AVG (?, 300)\n",
      "t_avg (?, 300)\n",
      "c_r (?, 300)\n",
      "t_r (?, 300)\n",
      "d (?, 600)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Target (InputLayer)             (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)        (None, 11, 300)      997200      Context[0][0]                    \n",
      "                                                                 Target[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_C (LSTM)                   [(None, 11, 300), (N 721200      embedding_34[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_T (LSTM)                   [(None, 11, 300), (N 721200      embedding_34[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "POOL_T (GlobalAveragePooling1D) (None, 300)          0           LSTM_T[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "POOL_C (GlobalAveragePooling1D) (None, 300)          0           LSTM_C[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 300)          0           LSTM_C[0][0]                     \n",
      "                                                                 POOL_T[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 300)          0           LSTM_T[0][0]                     \n",
      "                                                                 POOL_C[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 600)          0           lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 313)          188113      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 27)           8478        dense_37[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,636,191\n",
      "Trainable params: 1,638,991\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "IAN_model_1=Model_IAN_1_aspect(learning_rate=0.01,\n",
    "                     dropout=0.5,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 21s 18ms/step - loss: 2.6849 - acc: 0.3564\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 12s 11ms/step - loss: 2.4885 - acc: 0.3785\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 2.2855 - acc: 0.3964\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 2.1460 - acc: 0.4203\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.9835 - acc: 0.4510\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 1.8017 - acc: 0.4910\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 1.6241 - acc: 0.5448\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 1.5103 - acc: 0.5797\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 1.4060 - acc: 0.5703\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 1.2116 - acc: 0.6411\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 1.2204 - acc: 0.6402\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 1.1144 - acc: 0.6556\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.9482 - acc: 0.7033\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.8192 - acc: 0.7357\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.7293 - acc: 0.7758\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.6454 - acc: 0.7860\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.5596 - acc: 0.8235\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.4554 - acc: 0.8525\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.4177 - acc: 0.8747\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.4423 - acc: 0.8653\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.2907 - acc: 0.9088\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 13s 12ms/step - loss: 0.2600 - acc: 0.9250\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1992 - acc: 0.9420\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.2279 - acc: 0.9344\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.2097 - acc: 0.9386\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1277 - acc: 0.9616\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1801 - acc: 0.9565\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0852 - acc: 0.9795\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0819 - acc: 0.9795\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0654 - acc: 0.9787\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0480 - acc: 0.9872\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0429 - acc: 0.9906\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0286 - acc: 0.9940\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0706 - acc: 0.9855\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.1175 - acc: 0.9633\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0825 - acc: 0.9761\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0531 - acc: 0.9872\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0464 - acc: 0.9872\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0402 - acc: 0.9923\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0277 - acc: 0.9915\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0420 - acc: 0.9923\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0745 - acc: 0.9804\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0414 - acc: 0.9906\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0373 - acc: 0.9915\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 13s 11ms/step - loss: 0.0247 - acc: 0.9966\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 15s 13ms/step - loss: 0.0296 - acc: 0.9932\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 15s 13ms/step - loss: 0.0396 - acc: 0.9855\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 15s 13ms/step - loss: 0.0997 - acc: 0.9804\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0590 - acc: 0.9821\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 14s 12ms/step - loss: 0.0464 - acc: 0.9864\n"
     ]
    }
   ],
   "source": [
    "IAN_model_1 = IAN_model_1.fit(x=trainX,y=aspect, epochs=50,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After 50 epochs: loss: 0.0464 - acc: 0.9864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-d186051e9267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mIAN_model_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'IAN_MODEL_ASPECT.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "IAN_model_1.save('IAN_MODEL_ASPECT.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN+BIDIRECTIONAL LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model2(dropout,learning_rate,em,em_dim,lstm_out, n_hidden_layer,em_trainable_flag,n_filters=150):\n",
    "   \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    \n",
    "    c=Dropout(0.5)(context)\n",
    "    \n",
    "    c=Conv1D(n_filters,kernel_size=3,activation='relu')(context)\n",
    "    \n",
    "    m = Bidirectional(LSTM(150,return_sequences=False,recurrent_dropout=dropout))(c)\n",
    "                   \n",
    "    x=Dense(int((2*lstm_out+27)/2),activation='relu')(m)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(x)\n",
    "   \n",
    "    model= Model(inputs=input_context,outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Context (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "embedding_35 (Embedding)     (None, 11, 300)           997200    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 9, 150)            135150    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 300)               361200    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 313)               94213     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 27)                8478      \n",
      "=================================================================\n",
      "Total params: 1,596,241\n",
      "Trainable params: 599,041\n",
      "Non-trainable params: 997,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn_model_1 = define_model2(dropout=0.2,\n",
    "                     learning_rate=0.01,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 16s 14ms/step - loss: 2.6735 - acc: 0.3257\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 2.1954 - acc: 0.3887\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.8084 - acc: 0.4817\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.4574 - acc: 0.5772\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 1.1826 - acc: 0.6539\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.8284 - acc: 0.7698\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.5568 - acc: 0.8338\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.3825 - acc: 0.8764\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.2260 - acc: 0.9352\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.1814 - acc: 0.9454\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.1089 - acc: 0.9710\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0803 - acc: 0.9787\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0674 - acc: 0.9804\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0520 - acc: 0.9847\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0321 - acc: 0.9915\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0410 - acc: 0.9915\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0218 - acc: 0.9923\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0470 - acc: 0.9881\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0538 - acc: 0.9804\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0950 - acc: 0.9736\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0599 - acc: 0.9829\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0964 - acc: 0.9744\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.1163 - acc: 0.9633\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.1427 - acc: 0.9616\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.1482 - acc: 0.9668\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.1717 - acc: 0.9659\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.2334 - acc: 0.9488\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.1985 - acc: 0.9420\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.1148 - acc: 0.9642\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0562 - acc: 0.9787\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0440 - acc: 0.9847\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0253 - acc: 0.9915\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0141 - acc: 0.9906\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0103 - acc: 0.9940\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0107 - acc: 0.9940\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0102 - acc: 0.9923\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0081 - acc: 0.9957\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0089 - acc: 0.9940\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0085 - acc: 0.9932\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0082 - acc: 0.9949\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 5s 4ms/step - loss: 0.0076 - acc: 0.9940\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0076 - acc: 0.9932\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0085 - acc: 0.9940\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0079 - acc: 0.9932\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0092 - acc: 0.9923\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0076 - acc: 0.9949\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0088 - acc: 0.9940\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 5s 5ms/step - loss: 0.0078 - acc: 0.9940\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 0.0081 - acc: 0.9949\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 4s 4ms/step - loss: 0.0078 - acc: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183c4ea30b8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_1.fit(x=input_context,y=aspect, epochs=50,batch_size=64)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After 50 epochs: loss: 0.0078 - acc: 0.9949"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN +LSTM +ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model3(dropout,learning_rate,em,em_dim,lstm_out, n_hidden_layer,em_trainable_flag,n_filters=150):\n",
    "   \n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    context= embedding(input_context)\n",
    "    \n",
    "    c=Dropout(0.5)(context)\n",
    "    \n",
    "    c=Conv1D(n_filters,kernel_size=3,activation='relu')(context)\n",
    "    \n",
    "    m = Bidirectional(LSTM(150,return_sequences=True,recurrent_dropout=dropout))(c)\n",
    "    \n",
    "    a=  Attention()(m)\n",
    "                    \n",
    "    x=Dense(int((2*lstm_out+27)/2),activation='relu')(a)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(x)\n",
    "   \n",
    "    model= Model(inputs=input_context,outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Context (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "embedding_36 (Embedding)     (None, 11, 300)           997200    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 9, 150)            135150    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 9, 300)            361200    \n",
      "_________________________________________________________________\n",
      "attention_4 (Attention)      (None, 300)               309       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 313)               94213     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 27)                8478      \n",
      "=================================================================\n",
      "Total params: 1,596,550\n",
      "Trainable params: 599,350\n",
      "Non-trainable params: 997,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn_model_3 = define_model3(dropout=0.2,\n",
    "                     learning_rate=0.01,\n",
    "                     lstm_out=300,\n",
    "                     n_hidden_layer=1,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_3.fit(x=input_context,y=aspect, epochs=50,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 50 epochs: loss: 0.0075 - acc: 0.9940"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CHANNEL CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model2(dropout,learning_rate,em,em_dim,em_trainable_flag,n_filters=100):\n",
    "    \n",
    "\n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    inputs1= embedding(input_context)\n",
    "    \n",
    "    \n",
    "    conv1 = Conv1D(filters=n_filters, kernel_size=3, activation='relu')(inputs1)\n",
    "    drop1 = Dropout(dropout)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    conv2 = Conv1D(filters=n_filters, kernel_size=4, activation='relu')(inputs1)\n",
    "    drop2 = Dropout(dropout)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    conv3 = Conv1D(filters=n_filters, kernel_size=5, activation='relu')(inputs1)\n",
    "    drop3 = Dropout(dropout)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    conv4 = Conv1D(filters=n_filters, kernel_size=2, activation='relu')(inputs1)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    pool4 = MaxPooling1D(pool_size=2)(drop4)\n",
    "    flat4 = Flatten()(pool4)\n",
    "    \n",
    "    conv5 = Conv1D(filters=n_filters, kernel_size=6, activation='relu')(inputs1)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "    pool5 = MaxPooling1D(pool_size=2)(drop5)\n",
    "    flat5 = Flatten()(pool5)\n",
    "    # merge\n",
    "    \n",
    "    merged = concatenate([flat1, flat2, flat3,flat4,flat5])\n",
    "    # interpretation\n",
    "                   \n",
    "    x=Dense(400,activation='relu')(merged)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(x)\n",
    "   \n",
    "    model= Model(inputs=input_context,outputs=out)\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 11, 300)      997200      Context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 9, 100)       90100       embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 8, 100)       120100      embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 7, 100)       150100      embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 10, 100)      60100       embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 6, 100)       180100      embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 9, 100)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 100)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 7, 100)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 10, 100)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 6, 100)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 4, 100)       0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 4, 100)       0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 3, 100)       0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 5, 100)       0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 3, 100)       0           dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 400)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 400)          0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 300)          0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 500)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 300)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 1900)         0           flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 400)          760400      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 27)           10827       dense_45[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,368,927\n",
      "Trainable params: 1,371,727\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn_model_2 = cnn_model2(dropout=0.5,\n",
    "                     learning_rate=0.001,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 11s 9ms/step - loss: 2.5941 - acc: 0.3598\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 1.9396 - acc: 0.4612\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 1.3537 - acc: 0.6351\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.8588 - acc: 0.7818\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.4964 - acc: 0.8909\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.2531 - acc: 0.9531\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.1288 - acc: 0.9847\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 3s 2ms/step - loss: 0.0931 - acc: 0.9829\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 3s 2ms/step - loss: 0.0734 - acc: 0.9898\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0607 - acc: 0.9906\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0471 - acc: 0.9906\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0407 - acc: 0.9940\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0469 - acc: 0.9940\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0636 - acc: 0.9940\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0528 - acc: 0.9940\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0567 - acc: 0.9923\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0361 - acc: 0.9940\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0469 - acc: 0.9932\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0432 - acc: 0.9932\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0436 - acc: 0.9957\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0383 - acc: 0.9940\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0394 - acc: 0.9940\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0513 - acc: 0.9923\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0384 - acc: 0.9949\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0301 - acc: 0.9949\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0339 - acc: 0.9932\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0378 - acc: 0.9949\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0347 - acc: 0.9940\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0351 - acc: 0.9957\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0324 - acc: 0.9949\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0279 - acc: 0.9957\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0279 - acc: 0.9940\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0338 - acc: 0.9957\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0355 - acc: 0.9940\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0378 - acc: 0.9949\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0274 - acc: 0.9923\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0347 - acc: 0.9940\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0410 - acc: 0.9923\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0277 - acc: 0.9932\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0339 - acc: 0.9966\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0318 - acc: 0.9949\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0310 - acc: 0.9940\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0305 - acc: 0.9940\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0261 - acc: 0.9949\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0244 - acc: 0.9940\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0261 - acc: 0.9949\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0254 - acc: 0.9932\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0221 - acc: 0.9957\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0230 - acc: 0.9957\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 2s 2ms/step - loss: 0.0214 - acc: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183cffebba8>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_2.fit(x=input_context,y=aspect, epochs=50,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 50 epochs:  loss: 0.0214 - acc: 0.9957"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_4(dropout,learning_rate,em,em_dim,em_trainable_flag,num_filters=100):\n",
    "    \n",
    "  \n",
    "    filter_sizes = [3,4,5]\n",
    "\n",
    "\n",
    "    input_context= Input(shape=(max_length,),name='Context')\n",
    "    \n",
    "    embedding=Embedding(vocab_size, len(eval(em)[0]), weights = [eval(em)],input_length=max_length,trainable = em_trainable_flag)\n",
    "    inputs1= embedding(input_context)\n",
    "    \n",
    "    reshape = Reshape((max_length,em_dim,1))(inputs1)\n",
    "\n",
    "    c0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], em_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "    c1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], em_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "    c2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], em_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "    DP0 = MaxPooling2D(pool_size=(3, 1), strides=(1,1), padding='valid')(c0)\n",
    "    DP1 = MaxPooling2D(pool_size=(4, 1), strides=(1,1), padding='valid')(c1)\n",
    "    DP2 = MaxPooling2D(pool_size=(5, 1), strides=(1,1), padding='valid')(c2)\n",
    "\n",
    "    CT = Concatenate(axis=1)([DP0, DP1, DP2])\n",
    "\n",
    "    flatten = Flatten()(CT)\n",
    "    dropout = Dropout(dropout)(flatten)\n",
    "\n",
    "    x=Dense(400,activation='relu')(dropout)\n",
    "        \n",
    "    out=Dense(27,activation='softmax')(x)\n",
    "   \n",
    "    model= Model(inputs=input_context,outputs=out)\n",
    "    \n",
    "    checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "    \n",
    "    optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    #optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context (InputLayer)            (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 11, 300)      997200      Context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 11, 300, 1)   0           embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 1, 100)    90100       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 1, 100)    120100      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 1, 100)    150100      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 7, 1, 100)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 5, 1, 100)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 3, 1, 100)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 15, 1, 100)   0           max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 1500)         0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 1500)         0           flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 400)          600400      dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 27)           10827       dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,968,727\n",
      "Trainable params: 971,527\n",
      "Non-trainable params: 997,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn_model_4 = cnn_4(dropout=0.2,\n",
    "                     learning_rate=0.001,\n",
    "                     em='embedding_matrix',\n",
    "                     em_trainable_flag=False,\n",
    "                     em_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1173/1173 [==============================] - 6s 5ms/step - loss: 2.8157 - acc: 0.3350\n",
      "Epoch 2/50\n",
      "1173/1173 [==============================] - 1s 784us/step - loss: 2.5351 - acc: 0.3725\n",
      "Epoch 3/50\n",
      "1173/1173 [==============================] - 1s 847us/step - loss: 2.4314 - acc: 0.3734\n",
      "Epoch 4/50\n",
      "1173/1173 [==============================] - 1s 816us/step - loss: 2.3218 - acc: 0.3768\n",
      "Epoch 5/50\n",
      "1173/1173 [==============================] - 1s 921us/step - loss: 2.2259 - acc: 0.3930\n",
      "Epoch 6/50\n",
      "1173/1173 [==============================] - 1s 856us/step - loss: 2.1346 - acc: 0.4126\n",
      "Epoch 7/50\n",
      "1173/1173 [==============================] - 1s 885us/step - loss: 2.0219 - acc: 0.4373\n",
      "Epoch 8/50\n",
      "1173/1173 [==============================] - 1s 929us/step - loss: 1.9134 - acc: 0.4757\n",
      "Epoch 9/50\n",
      "1173/1173 [==============================] - 1s 878us/step - loss: 1.7896 - acc: 0.5072\n",
      "Epoch 10/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 1.6998 - acc: 0.5413\n",
      "Epoch 11/50\n",
      "1173/1173 [==============================] - 1s 841us/step - loss: 1.5813 - acc: 0.5754\n",
      "Epoch 12/50\n",
      "1173/1173 [==============================] - 1s 900us/step - loss: 1.4754 - acc: 0.6078\n",
      "Epoch 13/50\n",
      "1173/1173 [==============================] - 1s 817us/step - loss: 1.3898 - acc: 0.6581\n",
      "Epoch 14/50\n",
      "1173/1173 [==============================] - 1s 838us/step - loss: 1.2834 - acc: 0.6846\n",
      "Epoch 15/50\n",
      "1173/1173 [==============================] - 1s 867us/step - loss: 1.1865 - acc: 0.7195\n",
      "Epoch 16/50\n",
      "1173/1173 [==============================] - 1s 939us/step - loss: 1.0946 - acc: 0.7562\n",
      "Epoch 17/50\n",
      "1173/1173 [==============================] - 1s 924us/step - loss: 1.0261 - acc: 0.7664 0s - loss: 1.0125 - ac\n",
      "Epoch 18/50\n",
      "1173/1173 [==============================] - 1s 954us/step - loss: 0.9386 - acc: 0.7920\n",
      "Epoch 19/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.8750 - acc: 0.8116\n",
      "Epoch 20/50\n",
      "1173/1173 [==============================] - 1s 991us/step - loss: 0.7960 - acc: 0.8227 0s - loss: 0.8229\n",
      "Epoch 21/50\n",
      "1173/1173 [==============================] - 1s 968us/step - loss: 0.7285 - acc: 0.8491\n",
      "Epoch 22/50\n",
      "1173/1173 [==============================] - 1s 948us/step - loss: 0.6750 - acc: 0.8662\n",
      "Epoch 23/50\n",
      "1173/1173 [==============================] - 1s 933us/step - loss: 0.6203 - acc: 0.8875\n",
      "Epoch 24/50\n",
      "1173/1173 [==============================] - 1s 972us/step - loss: 0.5680 - acc: 0.8994\n",
      "Epoch 25/50\n",
      "1173/1173 [==============================] - 1s 983us/step - loss: 0.5285 - acc: 0.9096\n",
      "Epoch 26/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.4832 - acc: 0.9233\n",
      "Epoch 27/50\n",
      "1173/1173 [==============================] - 1s 934us/step - loss: 0.4321 - acc: 0.9429\n",
      "Epoch 28/50\n",
      "1173/1173 [==============================] - 1s 941us/step - loss: 0.4069 - acc: 0.9463\n",
      "Epoch 29/50\n",
      "1173/1173 [==============================] - 1s 925us/step - loss: 0.3703 - acc: 0.9514\n",
      "Epoch 30/50\n",
      "1173/1173 [==============================] - 1s 938us/step - loss: 0.3418 - acc: 0.9574 0s - loss: 0.3540 - a\n",
      "Epoch 31/50\n",
      "1173/1173 [==============================] - 1s 915us/step - loss: 0.3167 - acc: 0.9608\n",
      "Epoch 32/50\n",
      "1173/1173 [==============================] - 1s 934us/step - loss: 0.2931 - acc: 0.9676\n",
      "Epoch 33/50\n",
      "1173/1173 [==============================] - 1s 996us/step - loss: 0.2721 - acc: 0.9761\n",
      "Epoch 34/50\n",
      "1173/1173 [==============================] - 1s 974us/step - loss: 0.2480 - acc: 0.9770\n",
      "Epoch 35/50\n",
      "1173/1173 [==============================] - 1s 973us/step - loss: 0.2318 - acc: 0.9778 0s - loss: 0.2321 - acc: 0.977\n",
      "Epoch 36/50\n",
      "1173/1173 [==============================] - 1s 991us/step - loss: 0.2109 - acc: 0.9847\n",
      "Epoch 37/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.1992 - acc: 0.9812\n",
      "Epoch 38/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.1792 - acc: 0.9889\n",
      "Epoch 39/50\n",
      "1173/1173 [==============================] - 1s 983us/step - loss: 0.1700 - acc: 0.9864\n",
      "Epoch 40/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.1543 - acc: 0.9906\n",
      "Epoch 41/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.1462 - acc: 0.9898\n",
      "Epoch 42/50\n",
      "1173/1173 [==============================] - 1s 994us/step - loss: 0.1372 - acc: 0.9872\n",
      "Epoch 43/50\n",
      "1173/1173 [==============================] - 1s 994us/step - loss: 0.1305 - acc: 0.9881\n",
      "Epoch 44/50\n",
      "1173/1173 [==============================] - 1s 992us/step - loss: 0.1184 - acc: 0.9906\n",
      "Epoch 45/50\n",
      "1173/1173 [==============================] - 1s 956us/step - loss: 0.1154 - acc: 0.9872\n",
      "Epoch 46/50\n",
      "1173/1173 [==============================] - 1s 971us/step - loss: 0.1017 - acc: 0.9915\n",
      "Epoch 47/50\n",
      "1173/1173 [==============================] - 1s 995us/step - loss: 0.1007 - acc: 0.9906\n",
      "Epoch 48/50\n",
      "1173/1173 [==============================] - 1s 1ms/step - loss: 0.0940 - acc: 0.9915\n",
      "Epoch 49/50\n",
      "1173/1173 [==============================] - 1s 968us/step - loss: 0.0848 - acc: 0.9932\n",
      "Epoch 50/50\n",
      "1173/1173 [==============================] - 1s 996us/step - loss: 0.0837 - acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183d4dbf4e0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_4.fit(x=input_context,y=aspect, epochs=50,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 50 epochs:  loss: 0.0837 - acc: 0.9906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
